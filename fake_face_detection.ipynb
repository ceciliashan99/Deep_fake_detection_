{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 Project: Deep Fake Detection\n",
    "#### Group20: Name: SHAN Jinyun, SID: 55670256, EID: jshan9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "In this project, we are going to distinguish between fake faces and real faces with deep learning. Nowadays, it is quite cheap for anyone to create false faces, posing a threat to public privacy and safety. Thus, it is essential to figure out effective models to classify fake faces. With many trials, including but not limited to the upsampling on the datset, different data augmantation methods, and different model structures, the following model performs best. The code and the analysis are as follows, and the order is:\n",
    "1. Background\n",
    "2. Environment Setting \n",
    "3. Data Preprocessing \n",
    "4. Model Construction \n",
    "5. Training Process\n",
    "6. Testing\n",
    "7. Conclusion \n",
    "8. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "Fake faces may now be made with little or no effort and at a low cost of time and money. There might be two explanations for this: Free access to vast public databases, as well as rapid advancements in deep learning techniques, particularly Generative Adversarial Networks (GAN). There are a great number of free accesses to big size public databases, and the face images are available both through the datasets and the Internet. It provides a large amount of training data. Additionally, numerous deep learning techniques have been developed, which perform excellently when it comes to creating fake faces. Many of these are open resources that the general public may simply access. Therefore , developing models to recognize fake faces is critical for public safety and privacy.\n",
    "\n",
    "Fake faces may be divided into four categories. They are entire face synthesis, identity swap, attribute manipulation, and expression swap. Face synthesis builds entirely new faces from nothing. Identity swap replaces the face of one person with the face of another person, and it is commonly used in videos. Attribute manipulation modifies some attributes of the face, like the hair style. Expression Swap modifies the facial expression of the person, changing the facial expression of one person into another one’s and keep the original facial features.\n",
    "\n",
    "In this project, fake faces are generated by deepfake and face to face. Our task is to distinguish between fake faces and real faces, which turns into a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environmnet setting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Importing all the packages required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Setting the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Setting the random seed\n",
    "The random seed is specified here to ensure that the random state is consistent across all models. As a result, the outcomes of the models can be compared evenly.\n",
    "\n",
    "Note that we could always replicate the exactly same models by setting both the random seed and torch.backends.cudnn.deterministic = True under the same environment. To install the same environment, run the following command:\n",
    "\n",
    "``conda env create --name fake-face-detection -f fake-face-detection.yml``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "There are 4000 fake face images by face to face, 4000 fake face images by deepfake and 4000 real face images. There are three types of images, and the ration between fake faces and real faces is 2:1. \n",
    "\n",
    "To keep the data balanced, I tried to upsample the real faces while splitting the dataset. However, it may result in overfitting, and the typical unbalanced dataset ratio is 3:1. After the trials, it was discovered that models without upsampling outperform those with upsampling.\n",
    "\n",
    "After splitting, the training set, validation set, and test set have a ration of around 8:1:1. We will create jshon files first, then the Dataset and the Dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generating the json files\n",
    "Three json files containing the image paths and labels are created in this part. Fake face images are labeled as 0, and real face images are labeled as 1.  The training json file contains 9600 photos with 3200 images from each image type. The testing json file contains 1200 images from the original dataset, divided into 400 images for each image types. The validation json file contains 1200 images from the original dataset, with 400 images for each image types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1  Getting image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir1 = '/home/felix/disk1/sss/deepfake_detection/data/fake_deepfake'\n",
    "img_dir2 = '/home/felix/disk1/sss/deepfake_detection/data/fake_face2face'\n",
    "img_dir3 =  '/home/felix/disk1/sss/deepfake_detection/data/real'\n",
    "\n",
    "imgs = sorted(glob.glob('{:s}/*.png'.format(img_dir1)))\n",
    "imgs2 = sorted(glob.glob('{:s}/*.png'.format(img_dir2)))\n",
    "imgs3 = sorted(glob.glob('{:s}/*.png'.format(img_dir3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2  Generating random index\n",
    "\n",
    "The random index seeks to construct the training set, the testing set and the validation set by randomly selecting the data from the original dataset. Furthermore, because the random seed has already been determined, the datasets created are identical for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(0, 4000)]\n",
    "random.shuffle(index)\n",
    "train_index = index[0:3200]\n",
    "valid_index = index[3200:3600]\n",
    "test_index = index[3600:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Adding image paths and labels into the corresponding json files\n",
    " The images paths and labels are saved in the form of dictonary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {}\n",
    "items_valid = {}\n",
    "items_test = {}\n",
    "for i in range(4000):\n",
    "    sample_imgs = imgs[i]\n",
    "    label = 0\n",
    "    if i in train_index:\n",
    "        items[i] = {\n",
    "            'img_paths': sample_imgs,\n",
    "            'label': label\n",
    "        }\n",
    "    elif i in valid_index:\n",
    "        items_valid[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }\n",
    "    else:\n",
    "        items_test[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "train_index = [i + 4000 for i in train_index]\n",
    "valid_index = [i + 4000 for i in valid_index]\n",
    "test_index = [i + 4000 for i in test_index]\n",
    "for i in range(4000, 8000):\n",
    "    sample_imgs = imgs2[i-4000]\n",
    "    label = 0\n",
    "    if i in train_index:\n",
    "        items[i] = {\n",
    "            'img_paths': sample_imgs,\n",
    "            'label': label\n",
    "        }\n",
    "    elif i in valid_index:\n",
    "        items_valid[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }\n",
    "    else:\n",
    "        items_test[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "train_index = [i + 4000 for i in train_index]\n",
    "valid_index = [i + 4000 for i in valid_index]\n",
    "test_index = [i + 4000 for i in test_index]\n",
    "for i in range(8000, 12000):\n",
    "    sample_imgs = imgs3[i-8000]\n",
    "    label = 1\n",
    "    if i in train_index:\n",
    "        items[i] = {\n",
    "            'img_paths': sample_imgs,\n",
    "            'label': label\n",
    "        }\n",
    "    elif i in valid_index:\n",
    "        items_valid[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }\n",
    "    else:\n",
    "        items_test[i] = {\n",
    "            'img_paths': sample_imgs, \n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Saving the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_train = '/home/felix/disk1/sss/deepfake_detection/data/train_2-1.json'\n",
    "json_path_valid = '/home/felix/disk1/sss/deepfake_detection/data/valid_2-1.json'\n",
    "json_path_test = '/home/felix/disk1/sss/deepfake_detection/data/test_2-1.json'\n",
    "with open(json_path_train, 'w') as f:\n",
    "    json.dump(items, f, sort_keys=True, indent=4)\n",
    "with open(json_path_valid, 'w') as f:\n",
    "    json.dump(items_valid, f, sort_keys=True, indent=4)\n",
    "with open(json_path_test, 'w') as f:\n",
    "    json.dump(items_test, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Constructing the Dataset\n",
    "For the puropse of data augmentation and overfitting prevention, the methods applied here contains ramdom cropping, random horizontal flip, color jitter and noramlization. \n",
    "\n",
    "Randomly cropping a image into the size of 224*224 can not only satisfy the data augmentation, but also fit the default setting of ResNet, which would lead to a better result for the default parameters setting. \n",
    "\n",
    "The brightness, contrast, saturation, and hue of the images are changed randomly for the purpose of data augmentation and the prevention of overfitting on the training set. The brightness is the overall lightness or darkness of the image. The contrast refers to the amount of color or grayscale differentiation that exists between various image features in both analog and digital images. The saturation describes the intensity of the color, and the hue means the visible spectrum of basic colors that can be seen in a rainbow. The images are taken in different environments and of different people, so we change the properties above to increase the generality. \n",
    "\n",
    "After the trials, it shows that the model trained with random cropping, random horizontal flip and normalization performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imageset(Dataset):\n",
    "    def __init__(self, json_path, train = True):\n",
    "        f = open(json_path)\n",
    "        data = json.load(f)\n",
    "\n",
    "        self.items = []\n",
    "        for item in data.values():\n",
    "            term = {'img_paths': item['img_paths'], 'label': item['label']}  \n",
    "            self.items.append(term)\n",
    "    \n",
    "        if train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                # transforms.RandomVerticalFlip(),\n",
    "                # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
    "                # transforms.RandomAffine(degrees=10, translate=None, scale=(1, 2), shear=15, resample=False, fillcolor=0),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.items[idx]\n",
    "        img_paths = item['img_paths']\n",
    "        label = item['label']\n",
    "        img = Image.open(img_paths)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = int(label)\n",
    "        label = torch.LongTensor([label])[0]\n",
    "        \n",
    "        return {'imgs': img, 'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.3 Constructing the Dataloader\n",
    "The Dataloaders are built in this part using the Datasets construted before. The batch size for the training data is 32. The data would be shuffled so training images would be in different order for different epoch. It benefits the generality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Imageset('/home/felix/disk1/sss/deepfake_detection/data/train_2-1.json', train=True)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "valid_dataset = Imageset('/home/felix/disk1/sss/deepfake_detection/data/valid_2-1.json', train=False)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "test_dataset = Imageset('/home/felix/disk1/sss/deepfake_detection/data/test_2-1.json', train=False)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Model Construction\n",
    "The basic model applied in this project is ResNet50. Its invention addresses the issue of neural network degradation. It contains additional residual learning when compared to VGG19. Shortcut connections are added between some units. It would extract the output of previous networks and combine it with the output of the next several layers to form the input of subsequent networks. As a result, the networks in the middle are only required to acquire the knowledge of the residual. Therefore, the model can converge faster and achieve better results. \n",
    "\n",
    "The basic structure given in Pytorch suggests an input of size 224, and the output size is 1000. There are 4 basicblocks, and each basicblock contains several bottlenecks. In each bottleneck, there are 3 convolution layers, and there are 48 convolution layers totally. For the purpose of the classification task, a linear layer with ReLU activation function ans a linear layer converting 1000 outputs into 2 are added. The detailed structure is shown as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet(\n",
       "  (slice1): Sequential(\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (slice2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class resnet(torch.nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(resnet, self).__init__()\n",
    "        if pretrained == True:\n",
    "            model = models.resnet50(pretrained = True)\n",
    "        else:\n",
    "            model = models.resnet50(pretrained = False)\n",
    "        # model.conv1.in_channels = 3\n",
    "\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice1.add_module(str(1), model.conv1)\n",
    "        self.slice1.add_module(str(2), model.bn1)\n",
    "        self.slice1.add_module(str(3), model.relu)\n",
    "        self.slice1.add_module(str(4), model.maxpool)\n",
    "        self.slice1.add_module(str(5), model.layer1)\n",
    "        self.slice1.add_module(str(6), model.layer2)\n",
    "        self.slice1.add_module(str(7), model.layer3)\n",
    "        \n",
    "        model_other = models.resnet50(pretrained = False)\n",
    "\n",
    "        self.slice2 = model_other.layer4\n",
    "        self.avgpool = model_other.avgpool\n",
    "\n",
    "        self.classifier = torch.nn.Sequential()\n",
    "        self.classifier.add_module(str(1), model_other.fc)\n",
    "        self.classifier.add_module(str(2), torch.nn.ReLU(inplace=True))\n",
    "        self.classifier.add_module(str(3), torch.nn.Linear(1000, 2))\n",
    "        # self.classifier.add_module(str(3), torch.nn.Dropout())\n",
    "        # self.classifier.add_module(str(4), torch.nn.Linear(1000, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.slice1(x)\n",
    "        x = self.slice2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "resnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Setting the tensorboard and preparing to save the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger_dir = './tb_logger/'\n",
    "exp_name = 'aug3_v2'\n",
    "tb_logger = SummaryWriter(log_dir=tb_logger_dir + exp_name)\n",
    "\n",
    "def log_and_print(logger, message):\n",
    "    logger.write(message+'\\n')\n",
    "    logger.flush()\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = os.path.join('./experiments', exp_name)\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "logger = open(os.path.join(experiment_dir, 'train.log'), 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Defining the hyperparameters\n",
    "The optimizer applied here is Adaptive Moment Estimation (Adam), which combines root mean square propagation (RMSprop) and momentum. It shows great performance for model training. The following is the the formula.\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "m_{t}=\\mu * m_{t-1}+(1-\\mu) * g_{t} \\\\\n",
    "n_{t}=\\nu * n_{t-1}+(1-\\nu) * g_{t}^{2} \\\\\n",
    "\\hat{m}_{t}=\\frac{m_{t}}{1-\\mu^{t}} \\\\\n",
    "\\hat{n_{t}}=\\frac{n_{t}}{1-\\nu^{t}} \\\\\n",
    "\\Delta \\theta_{t}=-\\frac{\\hat{m}_{t}}{\\sqrt{\\hat{n_{t}}}+\\epsilon} * \\eta\n",
    "\\end{array}\n",
    "$$\n",
    "where $m_t$ is the exponential decay rate for the first moment estimates, $n_t$ is the exponential decay rate for the second-moment estimates, $\\hat{m}_{t}$ and $\\hat{n_{t}}$ are the updates for $m_t$ and $n_t$.\n",
    "\n",
    "The criterion is the cross entropy loss between input and target, which is commonly used for classification problem. \n",
    "\n",
    "We also apply a scheduler for learning rate here to achieve a better model. With the scheduler, the learning rate would be reduced by the factor 0.5 if there is no improvement on the model parameters for the maximum patience epoch 10. The learning rate at the beginning is $2*10^{-4}$, and the lower bound for the learning rate is $10^{-6}$. In this case, we can get a faster convergence at the beginning with relatively big learning rates and then get a preciser model with relatively small learning rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer, scheduler, and loss\n",
    "model = resnet(pretrained = True).cuda()\n",
    "learning_rate = 2e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)\n",
    "n_epochs = 200\n",
    "current_step = 0\n",
    "valid_loss_min = math.inf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Training the model\n",
    "The model is trained with the training data, and evaluted with the validation data. The best model is saved at the minimum loss on the validation data. The loss, accuracy, precision, and recall are recorded at the tensorboard for both the training set and the validation set for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 0. Learning rate: 2.0000e-04\n",
      "epoch = 0 | current step = 100 | train loss = 0.1845\n",
      "epoch = 0 | current step = 200 | train loss = 0.1803\n",
      "epoch = 0 | current step = 300 | train loss = 0.0238\n",
      "Average train loss: 0.260384\n",
      "\n",
      "Validating epoch: 0\n",
      "epoch = 0 | i = 0 | valid loss = 0.0000\n",
      "epoch = 0 | i = 500 | valid loss = 0.0000\n",
      "epoch = 0 | i = 1000 | valid loss = 1.6779\n",
      "Average valid loss: 0.158219 | Accuracy: 0.9417 | Recall: 0.8750 | Precision: 0.9459\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 1. Learning rate: 2.0000e-04\n",
      "epoch = 1 | current step = 400 | train loss = 0.0660\n",
      "epoch = 1 | current step = 500 | train loss = 0.1375\n",
      "epoch = 1 | current step = 600 | train loss = 0.1671\n",
      "Average train loss: 0.119841\n",
      "\n",
      "Validating epoch: 1\n",
      "epoch = 1 | i = 0 | valid loss = 0.0000\n",
      "epoch = 1 | i = 500 | valid loss = 0.0002\n",
      "epoch = 1 | i = 1000 | valid loss = 0.0021\n",
      "Average valid loss: 0.085271 | Accuracy: 0.9683 | Recall: 0.9500 | Precision: 0.9548\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 2. Learning rate: 2.0000e-04\n",
      "epoch = 2 | current step = 700 | train loss = 0.0797\n",
      "epoch = 2 | current step = 800 | train loss = 0.0648\n",
      "epoch = 2 | current step = 900 | train loss = 0.0437\n",
      "Average train loss: 0.099517\n",
      "\n",
      "Validating epoch: 2\n",
      "epoch = 2 | i = 0 | valid loss = 0.0018\n",
      "epoch = 2 | i = 500 | valid loss = 0.0000\n",
      "epoch = 2 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.232022 | Accuracy: 0.9017 | Recall: 1.0000 | Precision: 0.7722\n",
      "\n",
      "Training epoch: 3. Learning rate: 2.0000e-04\n",
      "epoch = 3 | current step = 1000 | train loss = 0.0396\n",
      "epoch = 3 | current step = 1100 | train loss = 0.0285\n",
      "epoch = 3 | current step = 1200 | train loss = 0.2087\n",
      "Average train loss: 0.079491\n",
      "\n",
      "Validating epoch: 3\n",
      "epoch = 3 | i = 0 | valid loss = 0.0000\n",
      "epoch = 3 | i = 500 | valid loss = 0.0000\n",
      "epoch = 3 | i = 1000 | valid loss = 0.0028\n",
      "Average valid loss: 0.063222 | Accuracy: 0.9750 | Recall: 0.9850 | Precision: 0.9426\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 4. Learning rate: 2.0000e-04\n",
      "epoch = 4 | current step = 1300 | train loss = 0.0573\n",
      "epoch = 4 | current step = 1400 | train loss = 0.0603\n",
      "epoch = 4 | current step = 1500 | train loss = 0.0321\n",
      "Average train loss: 0.073617\n",
      "\n",
      "Validating epoch: 4\n",
      "epoch = 4 | i = 0 | valid loss = 0.0000\n",
      "epoch = 4 | i = 500 | valid loss = 0.0000\n",
      "epoch = 4 | i = 1000 | valid loss = 0.0117\n",
      "Average valid loss: 0.054405 | Accuracy: 0.9808 | Recall: 0.9775 | Precision: 0.9654\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 5. Learning rate: 2.0000e-04\n",
      "epoch = 5 | current step = 1600 | train loss = 0.0386\n",
      "epoch = 5 | current step = 1700 | train loss = 0.0149\n",
      "epoch = 5 | current step = 1800 | train loss = 0.0412\n",
      "Average train loss: 0.065958\n",
      "\n",
      "Validating epoch: 5\n",
      "epoch = 5 | i = 0 | valid loss = 0.0000\n",
      "epoch = 5 | i = 500 | valid loss = 0.0000\n",
      "epoch = 5 | i = 1000 | valid loss = 0.0024\n",
      "Average valid loss: 0.046481 | Accuracy: 0.9850 | Recall: 0.9775 | Precision: 0.9775\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 6. Learning rate: 2.0000e-04\n",
      "epoch = 6 | current step = 1900 | train loss = 0.0224\n",
      "epoch = 6 | current step = 2000 | train loss = 0.0064\n",
      "epoch = 6 | current step = 2100 | train loss = 0.0529\n",
      "Average train loss: 0.051032\n",
      "\n",
      "Validating epoch: 6\n",
      "epoch = 6 | i = 0 | valid loss = 0.0000\n",
      "epoch = 6 | i = 500 | valid loss = 0.0000\n",
      "epoch = 6 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.077993 | Accuracy: 0.9708 | Recall: 0.9875 | Precision: 0.9294\n",
      "\n",
      "Training epoch: 7. Learning rate: 2.0000e-04\n",
      "epoch = 7 | current step = 2200 | train loss = 0.0061\n",
      "epoch = 7 | current step = 2300 | train loss = 0.0131\n",
      "epoch = 7 | current step = 2400 | train loss = 0.0763\n",
      "Average train loss: 0.057272\n",
      "\n",
      "Validating epoch: 7\n",
      "epoch = 7 | i = 0 | valid loss = 0.0000\n",
      "epoch = 7 | i = 500 | valid loss = 0.0000\n",
      "epoch = 7 | i = 1000 | valid loss = 0.0053\n",
      "Average valid loss: 0.048009 | Accuracy: 0.9800 | Recall: 0.9600 | Precision: 0.9796\n",
      "\n",
      "Training epoch: 8. Learning rate: 2.0000e-04\n",
      "epoch = 8 | current step = 2500 | train loss = 0.0047\n",
      "epoch = 8 | current step = 2600 | train loss = 0.0339\n",
      "epoch = 8 | current step = 2700 | train loss = 0.0123\n",
      "Average train loss: 0.049309\n",
      "\n",
      "Validating epoch: 8\n",
      "epoch = 8 | i = 0 | valid loss = 0.0000\n",
      "epoch = 8 | i = 500 | valid loss = 0.0000\n",
      "epoch = 8 | i = 1000 | valid loss = 0.0236\n",
      "Average valid loss: 0.096047 | Accuracy: 0.9583 | Recall: 0.8800 | Precision: 0.9944\n",
      "\n",
      "Training epoch: 9. Learning rate: 2.0000e-04\n",
      "epoch = 9 | current step = 2800 | train loss = 0.0266\n",
      "epoch = 9 | current step = 2900 | train loss = 0.0577\n",
      "epoch = 9 | current step = 3000 | train loss = 0.0234\n",
      "Average train loss: 0.042889\n",
      "\n",
      "Validating epoch: 9\n",
      "epoch = 9 | i = 0 | valid loss = 0.0000\n",
      "epoch = 9 | i = 500 | valid loss = 0.0000\n",
      "epoch = 9 | i = 1000 | valid loss = 0.1254\n",
      "Average valid loss: 0.290537 | Accuracy: 0.9183 | Recall: 0.7600 | Precision: 0.9935\n",
      "checkpoint at epoch 010 saved!\n",
      "\n",
      "Training epoch: 10. Learning rate: 2.0000e-04\n",
      "epoch = 10 | current step = 3100 | train loss = 0.0386\n",
      "epoch = 10 | current step = 3200 | train loss = 0.0395\n",
      "epoch = 10 | current step = 3300 | train loss = 0.0072\n",
      "Average train loss: 0.047934\n",
      "\n",
      "Validating epoch: 10\n",
      "epoch = 10 | i = 0 | valid loss = 0.0000\n",
      "epoch = 10 | i = 500 | valid loss = 0.0000\n",
      "epoch = 10 | i = 1000 | valid loss = 0.0010\n",
      "Average valid loss: 0.075428 | Accuracy: 0.9708 | Recall: 0.9775 | Precision: 0.9376\n",
      "\n",
      "Training epoch: 11. Learning rate: 2.0000e-04\n",
      "epoch = 11 | current step = 3400 | train loss = 0.0696\n",
      "epoch = 11 | current step = 3500 | train loss = 0.0447\n",
      "epoch = 11 | current step = 3600 | train loss = 0.1859\n",
      "Average train loss: 0.046451\n",
      "\n",
      "Validating epoch: 11\n",
      "epoch = 11 | i = 0 | valid loss = 0.0000\n",
      "epoch = 11 | i = 500 | valid loss = 0.0000\n",
      "epoch = 11 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.047611 | Accuracy: 0.9817 | Recall: 0.9900 | Precision: 0.9565\n",
      "\n",
      "Training epoch: 12. Learning rate: 2.0000e-04\n",
      "epoch = 12 | current step = 3700 | train loss = 0.0207\n",
      "epoch = 12 | current step = 3800 | train loss = 0.0449\n",
      "epoch = 12 | current step = 3900 | train loss = 0.0046\n",
      "Average train loss: 0.048394\n",
      "\n",
      "Validating epoch: 12\n",
      "epoch = 12 | i = 0 | valid loss = 0.0000\n",
      "epoch = 12 | i = 500 | valid loss = 0.0000\n",
      "epoch = 12 | i = 1000 | valid loss = 0.0104\n",
      "Average valid loss: 0.060089 | Accuracy: 0.9767 | Recall: 0.9675 | Precision: 0.9627\n",
      "\n",
      "Training epoch: 13. Learning rate: 2.0000e-04\n",
      "epoch = 13 | current step = 4000 | train loss = 0.0159\n",
      "epoch = 13 | current step = 4100 | train loss = 0.0112\n",
      "epoch = 13 | current step = 4200 | train loss = 0.0115\n",
      "Average train loss: 0.039986\n",
      "\n",
      "Validating epoch: 13\n",
      "epoch = 13 | i = 0 | valid loss = 0.0000\n",
      "epoch = 13 | i = 500 | valid loss = 0.0000\n",
      "epoch = 13 | i = 1000 | valid loss = 0.0146\n",
      "Average valid loss: 0.062542 | Accuracy: 0.9792 | Recall: 0.9875 | Precision: 0.9518\n",
      "\n",
      "Training epoch: 14. Learning rate: 2.0000e-04\n",
      "epoch = 14 | current step = 4300 | train loss = 0.0398\n",
      "epoch = 14 | current step = 4400 | train loss = 0.0097\n",
      "epoch = 14 | current step = 4500 | train loss = 0.0156\n",
      "Average train loss: 0.042441\n",
      "\n",
      "Validating epoch: 14\n",
      "epoch = 14 | i = 0 | valid loss = 0.0000\n",
      "epoch = 14 | i = 500 | valid loss = 0.0000\n",
      "epoch = 14 | i = 1000 | valid loss = 0.0012\n",
      "Average valid loss: 0.086310 | Accuracy: 0.9675 | Recall: 0.9750 | Precision: 0.9308\n",
      "\n",
      "Training epoch: 15. Learning rate: 2.0000e-04\n",
      "epoch = 15 | current step = 4600 | train loss = 0.0294\n",
      "epoch = 15 | current step = 4700 | train loss = 0.0011\n",
      "epoch = 15 | current step = 4800 | train loss = 0.0195\n",
      "Average train loss: 0.036748\n",
      "\n",
      "Validating epoch: 15\n",
      "epoch = 15 | i = 0 | valid loss = 0.0000\n",
      "epoch = 15 | i = 500 | valid loss = 0.0000\n",
      "epoch = 15 | i = 1000 | valid loss = 0.0004\n",
      "Average valid loss: 0.052456 | Accuracy: 0.9808 | Recall: 0.9950 | Precision: 0.9499\n",
      "\n",
      "Training epoch: 16. Learning rate: 2.0000e-04\n",
      "epoch = 16 | current step = 4900 | train loss = 0.0015\n",
      "epoch = 16 | current step = 5000 | train loss = 0.1682\n",
      "epoch = 16 | current step = 5100 | train loss = 0.0058\n",
      "Average train loss: 0.037281\n",
      "\n",
      "Validating epoch: 16\n",
      "epoch = 16 | i = 0 | valid loss = 0.0000\n",
      "epoch = 16 | i = 500 | valid loss = 0.0000\n",
      "epoch = 16 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.069372 | Accuracy: 0.9733 | Recall: 0.9725 | Precision: 0.9488\n",
      "\n",
      "Training epoch: 17. Learning rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17 | current step = 5200 | train loss = 0.0088\n",
      "epoch = 17 | current step = 5300 | train loss = 0.0155\n",
      "epoch = 17 | current step = 5400 | train loss = 0.0353\n",
      "Average train loss: 0.020009\n",
      "\n",
      "Validating epoch: 17\n",
      "epoch = 17 | i = 0 | valid loss = 0.0000\n",
      "epoch = 17 | i = 500 | valid loss = 0.0000\n",
      "epoch = 17 | i = 1000 | valid loss = 0.0017\n",
      "Average valid loss: 0.075531 | Accuracy: 0.9767 | Recall: 0.9350 | Precision: 0.9947\n",
      "\n",
      "Training epoch: 18. Learning rate: 1.0000e-04\n",
      "epoch = 18 | current step = 5500 | train loss = 0.0008\n",
      "epoch = 18 | current step = 5600 | train loss = 0.0002\n",
      "epoch = 18 | current step = 5700 | train loss = 0.0021\n",
      "Average train loss: 0.015632\n",
      "\n",
      "Validating epoch: 18\n",
      "epoch = 18 | i = 0 | valid loss = 0.0000\n",
      "epoch = 18 | i = 500 | valid loss = 0.0000\n",
      "epoch = 18 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.036623 | Accuracy: 0.9883 | Recall: 0.9875 | Precision: 0.9777\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 19. Learning rate: 1.0000e-04\n",
      "epoch = 19 | current step = 5800 | train loss = 0.0014\n",
      "epoch = 19 | current step = 5900 | train loss = 0.0306\n",
      "epoch = 19 | current step = 6000 | train loss = 0.0001\n",
      "Average train loss: 0.012464\n",
      "\n",
      "Validating epoch: 19\n",
      "epoch = 19 | i = 0 | valid loss = 0.0000\n",
      "epoch = 19 | i = 500 | valid loss = 0.0000\n",
      "epoch = 19 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.047459 | Accuracy: 0.9858 | Recall: 0.9750 | Precision: 0.9824\n",
      "checkpoint at epoch 020 saved!\n",
      "\n",
      "Training epoch: 20. Learning rate: 1.0000e-04\n",
      "epoch = 20 | current step = 6100 | train loss = 0.0002\n",
      "epoch = 20 | current step = 6200 | train loss = 0.0025\n",
      "epoch = 20 | current step = 6300 | train loss = 0.0015\n",
      "Average train loss: 0.010141\n",
      "\n",
      "Validating epoch: 20\n",
      "epoch = 20 | i = 0 | valid loss = 0.0000\n",
      "epoch = 20 | i = 500 | valid loss = 0.0000\n",
      "epoch = 20 | i = 1000 | valid loss = 0.0006\n",
      "Average valid loss: 0.043416 | Accuracy: 0.9833 | Recall: 0.9650 | Precision: 0.9847\n",
      "\n",
      "Training epoch: 21. Learning rate: 1.0000e-04\n",
      "epoch = 21 | current step = 6400 | train loss = 0.0059\n",
      "epoch = 21 | current step = 6500 | train loss = 0.0016\n",
      "epoch = 21 | current step = 6600 | train loss = 0.0009\n",
      "Average train loss: 0.013714\n",
      "\n",
      "Validating epoch: 21\n",
      "epoch = 21 | i = 0 | valid loss = 0.0000\n",
      "epoch = 21 | i = 500 | valid loss = 0.0000\n",
      "epoch = 21 | i = 1000 | valid loss = 0.0002\n",
      "Average valid loss: 0.041642 | Accuracy: 0.9875 | Recall: 0.9775 | Precision: 0.9849\n",
      "\n",
      "Training epoch: 22. Learning rate: 1.0000e-04\n",
      "epoch = 22 | current step = 6700 | train loss = 0.0001\n",
      "epoch = 22 | current step = 6800 | train loss = 0.0984\n",
      "epoch = 22 | current step = 6900 | train loss = 0.0005\n",
      "Average train loss: 0.019329\n",
      "\n",
      "Validating epoch: 22\n",
      "epoch = 22 | i = 0 | valid loss = 0.0000\n",
      "epoch = 22 | i = 500 | valid loss = 0.0000\n",
      "epoch = 22 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.029609 | Accuracy: 0.9883 | Recall: 0.9825 | Precision: 0.9825\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 23. Learning rate: 1.0000e-04\n",
      "epoch = 23 | current step = 7000 | train loss = 0.0019\n",
      "epoch = 23 | current step = 7100 | train loss = 0.0015\n",
      "epoch = 23 | current step = 7200 | train loss = 0.0008\n",
      "Average train loss: 0.013644\n",
      "\n",
      "Validating epoch: 23\n",
      "epoch = 23 | i = 0 | valid loss = 0.0000\n",
      "epoch = 23 | i = 500 | valid loss = 0.0000\n",
      "epoch = 23 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.036113 | Accuracy: 0.9875 | Recall: 0.9700 | Precision: 0.9923\n",
      "\n",
      "Training epoch: 24. Learning rate: 1.0000e-04\n",
      "epoch = 24 | current step = 7300 | train loss = 0.0026\n",
      "epoch = 24 | current step = 7400 | train loss = 0.0041\n",
      "epoch = 24 | current step = 7500 | train loss = 0.0005\n",
      "Average train loss: 0.012422\n",
      "\n",
      "Validating epoch: 24\n",
      "epoch = 24 | i = 0 | valid loss = 0.0000\n",
      "epoch = 24 | i = 500 | valid loss = 0.0000\n",
      "epoch = 24 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.037931 | Accuracy: 0.9808 | Recall: 0.9650 | Precision: 0.9772\n",
      "\n",
      "Training epoch: 25. Learning rate: 1.0000e-04\n",
      "epoch = 25 | current step = 7600 | train loss = 0.0009\n",
      "epoch = 25 | current step = 7700 | train loss = 0.0004\n",
      "epoch = 25 | current step = 7800 | train loss = 0.0005\n",
      "Average train loss: 0.009877\n",
      "\n",
      "Validating epoch: 25\n",
      "epoch = 25 | i = 0 | valid loss = 0.0000\n",
      "epoch = 25 | i = 500 | valid loss = 0.0000\n",
      "epoch = 25 | i = 1000 | valid loss = 0.0002\n",
      "Average valid loss: 0.051961 | Accuracy: 0.9792 | Recall: 0.9725 | Precision: 0.9653\n",
      "\n",
      "Training epoch: 26. Learning rate: 1.0000e-04\n",
      "epoch = 26 | current step = 7900 | train loss = 0.0002\n",
      "epoch = 26 | current step = 8000 | train loss = 0.0396\n",
      "epoch = 26 | current step = 8100 | train loss = 0.0425\n",
      "Average train loss: 0.016462\n",
      "\n",
      "Validating epoch: 26\n",
      "epoch = 26 | i = 0 | valid loss = 0.0000\n",
      "epoch = 26 | i = 500 | valid loss = 0.0000\n",
      "epoch = 26 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.054992 | Accuracy: 0.9758 | Recall: 0.9425 | Precision: 0.9843\n",
      "\n",
      "Training epoch: 27. Learning rate: 1.0000e-04\n",
      "epoch = 27 | current step = 8200 | train loss = 0.0197\n",
      "epoch = 27 | current step = 8300 | train loss = 0.0014\n",
      "epoch = 27 | current step = 8400 | train loss = 0.0004\n",
      "Average train loss: 0.012575\n",
      "\n",
      "Validating epoch: 27\n",
      "epoch = 27 | i = 0 | valid loss = 0.0000\n",
      "epoch = 27 | i = 500 | valid loss = 0.0000\n",
      "epoch = 27 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.027390 | Accuracy: 0.9892 | Recall: 0.9850 | Precision: 0.9825\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 28. Learning rate: 1.0000e-04\n",
      "epoch = 28 | current step = 8500 | train loss = 0.0005\n",
      "epoch = 28 | current step = 8600 | train loss = 0.0181\n",
      "epoch = 28 | current step = 8700 | train loss = 0.0023\n",
      "Average train loss: 0.013026\n",
      "\n",
      "Validating epoch: 28\n",
      "epoch = 28 | i = 0 | valid loss = 0.0000\n",
      "epoch = 28 | i = 500 | valid loss = 0.0000\n",
      "epoch = 28 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059365 | Accuracy: 0.9833 | Recall: 0.9725 | Precision: 0.9774\n",
      "\n",
      "Training epoch: 29. Learning rate: 1.0000e-04\n",
      "epoch = 29 | current step = 8800 | train loss = 0.0026\n",
      "epoch = 29 | current step = 8900 | train loss = 0.0008\n",
      "epoch = 29 | current step = 9000 | train loss = 0.1416\n",
      "Average train loss: 0.011177\n",
      "\n",
      "Validating epoch: 29\n",
      "epoch = 29 | i = 0 | valid loss = 0.0000\n",
      "epoch = 29 | i = 500 | valid loss = 0.0000\n",
      "epoch = 29 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.033106 | Accuracy: 0.9933 | Recall: 0.9925 | Precision: 0.9876\n",
      "checkpoint at epoch 030 saved!\n",
      "\n",
      "Training epoch: 30. Learning rate: 1.0000e-04\n",
      "epoch = 30 | current step = 9100 | train loss = 0.0000\n",
      "epoch = 30 | current step = 9200 | train loss = 0.0011\n",
      "epoch = 30 | current step = 9300 | train loss = 0.0028\n",
      "Average train loss: 0.013149\n",
      "\n",
      "Validating epoch: 30\n",
      "epoch = 30 | i = 0 | valid loss = 0.0000\n",
      "epoch = 30 | i = 500 | valid loss = 0.0000\n",
      "epoch = 30 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049138 | Accuracy: 0.9842 | Recall: 0.9900 | Precision: 0.9635\n",
      "\n",
      "Training epoch: 31. Learning rate: 1.0000e-04\n",
      "epoch = 31 | current step = 9400 | train loss = 0.0024\n",
      "epoch = 31 | current step = 9500 | train loss = 0.0680\n",
      "epoch = 31 | current step = 9600 | train loss = 0.0003\n",
      "Average train loss: 0.015892\n",
      "\n",
      "Validating epoch: 31\n",
      "epoch = 31 | i = 0 | valid loss = 0.0000\n",
      "epoch = 31 | i = 500 | valid loss = 0.0000\n",
      "epoch = 31 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.042480 | Accuracy: 0.9883 | Recall: 0.9825 | Precision: 0.9825\n",
      "\n",
      "Training epoch: 32. Learning rate: 1.0000e-04\n",
      "epoch = 32 | current step = 9700 | train loss = 0.0009\n",
      "epoch = 32 | current step = 9800 | train loss = 0.0003\n",
      "epoch = 32 | current step = 9900 | train loss = 0.0001\n",
      "Average train loss: 0.008897\n",
      "\n",
      "Validating epoch: 32\n",
      "epoch = 32 | i = 0 | valid loss = 0.0000\n",
      "epoch = 32 | i = 500 | valid loss = 0.0000\n",
      "epoch = 32 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.038197 | Accuracy: 0.9900 | Recall: 0.9775 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 33. Learning rate: 1.0000e-04\n",
      "epoch = 33 | current step = 10000 | train loss = 0.0006\n",
      "epoch = 33 | current step = 10100 | train loss = 0.0229\n",
      "epoch = 33 | current step = 10200 | train loss = 0.0027\n",
      "Average train loss: 0.010864\n",
      "\n",
      "Validating epoch: 33\n",
      "epoch = 33 | i = 0 | valid loss = 0.0000\n",
      "epoch = 33 | i = 500 | valid loss = 0.0000\n",
      "epoch = 33 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.043109 | Accuracy: 0.9825 | Recall: 0.9575 | Precision: 0.9897\n",
      "\n",
      "Training epoch: 34. Learning rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 34 | current step = 10300 | train loss = 0.1215\n",
      "epoch = 34 | current step = 10400 | train loss = 0.0001\n",
      "epoch = 34 | current step = 10500 | train loss = 0.0025\n",
      "Average train loss: 0.011304\n",
      "\n",
      "Validating epoch: 34\n",
      "epoch = 34 | i = 0 | valid loss = 0.0000\n",
      "epoch = 34 | i = 500 | valid loss = 0.0000\n",
      "epoch = 34 | i = 1000 | valid loss = 0.0002\n",
      "Average valid loss: 0.047619 | Accuracy: 0.9842 | Recall: 0.9800 | Precision: 0.9727\n",
      "\n",
      "Training epoch: 35. Learning rate: 1.0000e-04\n",
      "epoch = 35 | current step = 10600 | train loss = 0.0006\n",
      "epoch = 35 | current step = 10700 | train loss = 0.0003\n",
      "epoch = 35 | current step = 10800 | train loss = 0.0004\n",
      "Average train loss: 0.010883\n",
      "\n",
      "Validating epoch: 35\n",
      "epoch = 35 | i = 0 | valid loss = 0.0000\n",
      "epoch = 35 | i = 500 | valid loss = 0.0000\n",
      "epoch = 35 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.041684 | Accuracy: 0.9867 | Recall: 0.9825 | Precision: 0.9776\n",
      "\n",
      "Training epoch: 36. Learning rate: 1.0000e-04\n",
      "epoch = 36 | current step = 10900 | train loss = 0.0002\n",
      "epoch = 36 | current step = 11000 | train loss = 0.0015\n",
      "epoch = 36 | current step = 11100 | train loss = 0.0072\n",
      "Average train loss: 0.010371\n",
      "\n",
      "Validating epoch: 36\n",
      "epoch = 36 | i = 0 | valid loss = 0.0000\n",
      "epoch = 36 | i = 500 | valid loss = 0.0000\n",
      "epoch = 36 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.038110 | Accuracy: 0.9858 | Recall: 0.9725 | Precision: 0.9848\n",
      "\n",
      "Training epoch: 37. Learning rate: 1.0000e-04\n",
      "epoch = 37 | current step = 11200 | train loss = 0.0017\n",
      "epoch = 37 | current step = 11300 | train loss = 0.0027\n",
      "epoch = 37 | current step = 11400 | train loss = 0.0017\n",
      "Average train loss: 0.010470\n",
      "\n",
      "Validating epoch: 37\n",
      "epoch = 37 | i = 0 | valid loss = 0.0000\n",
      "epoch = 37 | i = 500 | valid loss = 0.0000\n",
      "epoch = 37 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.032635 | Accuracy: 0.9867 | Recall: 0.9875 | Precision: 0.9729\n",
      "\n",
      "Training epoch: 38. Learning rate: 1.0000e-04\n",
      "epoch = 38 | current step = 11500 | train loss = 0.0003\n",
      "epoch = 38 | current step = 11600 | train loss = 0.0005\n",
      "epoch = 38 | current step = 11700 | train loss = 0.0140\n",
      "Average train loss: 0.012951\n",
      "\n",
      "Validating epoch: 38\n",
      "epoch = 38 | i = 0 | valid loss = 0.0000\n",
      "epoch = 38 | i = 500 | valid loss = 0.0000\n",
      "epoch = 38 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.033420 | Accuracy: 0.9892 | Recall: 0.9850 | Precision: 0.9825\n",
      "\n",
      "Training epoch: 39. Learning rate: 5.0000e-05\n",
      "epoch = 39 | current step = 11800 | train loss = 0.0029\n",
      "epoch = 39 | current step = 11900 | train loss = 0.0007\n",
      "epoch = 39 | current step = 12000 | train loss = 0.0003\n",
      "Average train loss: 0.005281\n",
      "\n",
      "Validating epoch: 39\n",
      "epoch = 39 | i = 0 | valid loss = 0.0000\n",
      "epoch = 39 | i = 500 | valid loss = 0.0000\n",
      "epoch = 39 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.038679 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "checkpoint at epoch 040 saved!\n",
      "\n",
      "Training epoch: 40. Learning rate: 5.0000e-05\n",
      "epoch = 40 | current step = 12100 | train loss = 0.0276\n",
      "epoch = 40 | current step = 12200 | train loss = 0.0001\n",
      "epoch = 40 | current step = 12300 | train loss = 0.0340\n",
      "Average train loss: 0.003770\n",
      "\n",
      "Validating epoch: 40\n",
      "epoch = 40 | i = 0 | valid loss = 0.0000\n",
      "epoch = 40 | i = 500 | valid loss = 0.0000\n",
      "epoch = 40 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.031731 | Accuracy: 0.9867 | Recall: 0.9825 | Precision: 0.9776\n",
      "\n",
      "Training epoch: 41. Learning rate: 5.0000e-05\n",
      "epoch = 41 | current step = 12400 | train loss = 0.0073\n",
      "epoch = 41 | current step = 12500 | train loss = 0.0000\n",
      "epoch = 41 | current step = 12600 | train loss = 0.0018\n",
      "Average train loss: 0.002879\n",
      "\n",
      "Validating epoch: 41\n",
      "epoch = 41 | i = 0 | valid loss = 0.0000\n",
      "epoch = 41 | i = 500 | valid loss = 0.0000\n",
      "epoch = 41 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.036505 | Accuracy: 0.9925 | Recall: 0.9875 | Precision: 0.9900\n",
      "\n",
      "Training epoch: 42. Learning rate: 5.0000e-05\n",
      "epoch = 42 | current step = 12700 | train loss = 0.0012\n",
      "epoch = 42 | current step = 12800 | train loss = 0.0011\n",
      "epoch = 42 | current step = 12900 | train loss = 0.0000\n",
      "Average train loss: 0.001384\n",
      "\n",
      "Validating epoch: 42\n",
      "epoch = 42 | i = 0 | valid loss = 0.0000\n",
      "epoch = 42 | i = 500 | valid loss = 0.0000\n",
      "epoch = 42 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.072380 | Accuracy: 0.9867 | Recall: 0.9700 | Precision: 0.9898\n",
      "\n",
      "Training epoch: 43. Learning rate: 5.0000e-05\n",
      "epoch = 43 | current step = 13000 | train loss = 0.0000\n",
      "epoch = 43 | current step = 13100 | train loss = 0.0000\n",
      "epoch = 43 | current step = 13200 | train loss = 0.0003\n",
      "Average train loss: 0.005566\n",
      "\n",
      "Validating epoch: 43\n",
      "epoch = 43 | i = 0 | valid loss = 0.0000\n",
      "epoch = 43 | i = 500 | valid loss = 0.0000\n",
      "epoch = 43 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.073757 | Accuracy: 0.9808 | Recall: 0.9800 | Precision: 0.9631\n",
      "\n",
      "Training epoch: 44. Learning rate: 5.0000e-05\n",
      "epoch = 44 | current step = 13300 | train loss = 0.0091\n",
      "epoch = 44 | current step = 13400 | train loss = 0.0006\n",
      "epoch = 44 | current step = 13500 | train loss = 0.0000\n",
      "Average train loss: 0.005623\n",
      "\n",
      "Validating epoch: 44\n",
      "epoch = 44 | i = 0 | valid loss = 0.0000\n",
      "epoch = 44 | i = 500 | valid loss = 0.0000\n",
      "epoch = 44 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.019462 | Accuracy: 0.9933 | Recall: 0.9875 | Precision: 0.9925\n",
      "best checkpoint saved!\n",
      "\n",
      "Training epoch: 45. Learning rate: 5.0000e-05\n",
      "epoch = 45 | current step = 13600 | train loss = 0.0002\n",
      "epoch = 45 | current step = 13700 | train loss = 0.0001\n",
      "epoch = 45 | current step = 13800 | train loss = 0.0016\n",
      "Average train loss: 0.003049\n",
      "\n",
      "Validating epoch: 45\n",
      "epoch = 45 | i = 0 | valid loss = 0.0000\n",
      "epoch = 45 | i = 500 | valid loss = 0.0000\n",
      "epoch = 45 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.021799 | Accuracy: 0.9917 | Recall: 0.9900 | Precision: 0.9851\n",
      "\n",
      "Training epoch: 46. Learning rate: 5.0000e-05\n",
      "epoch = 46 | current step = 13900 | train loss = 0.0000\n",
      "epoch = 46 | current step = 14000 | train loss = 0.0001\n",
      "epoch = 46 | current step = 14100 | train loss = 0.0000\n",
      "Average train loss: 0.002667\n",
      "\n",
      "Validating epoch: 46\n",
      "epoch = 46 | i = 0 | valid loss = 0.0000\n",
      "epoch = 46 | i = 500 | valid loss = 0.0000\n",
      "epoch = 46 | i = 1000 | valid loss = 0.0001\n",
      "Average valid loss: 0.045258 | Accuracy: 0.9867 | Recall: 0.9675 | Precision: 0.9923\n",
      "\n",
      "Training epoch: 47. Learning rate: 5.0000e-05\n",
      "epoch = 47 | current step = 14200 | train loss = 0.0000\n",
      "epoch = 47 | current step = 14300 | train loss = 0.0119\n",
      "epoch = 47 | current step = 14400 | train loss = 0.0000\n",
      "Average train loss: 0.006173\n",
      "\n",
      "Validating epoch: 47\n",
      "epoch = 47 | i = 0 | valid loss = 0.0000\n",
      "epoch = 47 | i = 500 | valid loss = 0.0000\n",
      "epoch = 47 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.046949 | Accuracy: 0.9858 | Recall: 0.9850 | Precision: 0.9728\n",
      "\n",
      "Training epoch: 48. Learning rate: 5.0000e-05\n",
      "epoch = 48 | current step = 14500 | train loss = 0.0010\n",
      "epoch = 48 | current step = 14600 | train loss = 0.0003\n",
      "epoch = 48 | current step = 14700 | train loss = 0.0000\n",
      "Average train loss: 0.005841\n",
      "\n",
      "Validating epoch: 48\n",
      "epoch = 48 | i = 0 | valid loss = 0.0000\n",
      "epoch = 48 | i = 500 | valid loss = 0.0000\n",
      "epoch = 48 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.044584 | Accuracy: 0.9842 | Recall: 0.9600 | Precision: 0.9922\n",
      "\n",
      "Training epoch: 49. Learning rate: 5.0000e-05\n",
      "epoch = 49 | current step = 14800 | train loss = 0.0172\n",
      "epoch = 49 | current step = 14900 | train loss = 0.0005\n",
      "epoch = 49 | current step = 15000 | train loss = 0.0008\n",
      "Average train loss: 0.003094\n",
      "\n",
      "Validating epoch: 49\n",
      "epoch = 49 | i = 0 | valid loss = 0.0000\n",
      "epoch = 49 | i = 500 | valid loss = 0.0000\n",
      "epoch = 49 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.041429 | Accuracy: 0.9875 | Recall: 0.9700 | Precision: 0.9923\n",
      "checkpoint at epoch 050 saved!\n",
      "\n",
      "Training epoch: 50. Learning rate: 5.0000e-05\n",
      "epoch = 50 | current step = 15100 | train loss = 0.0000\n",
      "epoch = 50 | current step = 15200 | train loss = 0.0001\n",
      "epoch = 50 | current step = 15300 | train loss = 0.0169\n",
      "Average train loss: 0.001834\n",
      "\n",
      "Validating epoch: 50\n",
      "epoch = 50 | i = 0 | valid loss = 0.0000\n",
      "epoch = 50 | i = 500 | valid loss = 0.0000\n",
      "epoch = 50 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.069538 | Accuracy: 0.9867 | Recall: 0.9900 | Precision: 0.9706\n",
      "\n",
      "Training epoch: 51. Learning rate: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 51 | current step = 15400 | train loss = 0.0004\n",
      "epoch = 51 | current step = 15500 | train loss = 0.0000\n",
      "epoch = 51 | current step = 15600 | train loss = 0.0001\n",
      "Average train loss: 0.002819\n",
      "\n",
      "Validating epoch: 51\n",
      "epoch = 51 | i = 0 | valid loss = 0.0000\n",
      "epoch = 51 | i = 500 | valid loss = 0.0000\n",
      "epoch = 51 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.040010 | Accuracy: 0.9883 | Recall: 0.9775 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 52. Learning rate: 5.0000e-05\n",
      "epoch = 52 | current step = 15700 | train loss = 0.0008\n",
      "epoch = 52 | current step = 15800 | train loss = 0.0314\n",
      "epoch = 52 | current step = 15900 | train loss = 0.1170\n",
      "Average train loss: 0.004944\n",
      "\n",
      "Validating epoch: 52\n",
      "epoch = 52 | i = 0 | valid loss = 0.0000\n",
      "epoch = 52 | i = 500 | valid loss = 0.0000\n",
      "epoch = 52 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.048680 | Accuracy: 0.9858 | Recall: 0.9750 | Precision: 0.9824\n",
      "\n",
      "Training epoch: 53. Learning rate: 5.0000e-05\n",
      "epoch = 53 | current step = 16000 | train loss = 0.0002\n",
      "epoch = 53 | current step = 16100 | train loss = 0.0000\n",
      "epoch = 53 | current step = 16200 | train loss = 0.0005\n",
      "Average train loss: 0.002946\n",
      "\n",
      "Validating epoch: 53\n",
      "epoch = 53 | i = 0 | valid loss = 0.0000\n",
      "epoch = 53 | i = 500 | valid loss = 0.0000\n",
      "epoch = 53 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.039851 | Accuracy: 0.9875 | Recall: 0.9800 | Precision: 0.9825\n",
      "\n",
      "Training epoch: 54. Learning rate: 5.0000e-05\n",
      "epoch = 54 | current step = 16300 | train loss = 0.0001\n",
      "epoch = 54 | current step = 16400 | train loss = 0.0000\n",
      "epoch = 54 | current step = 16500 | train loss = 0.0000\n",
      "Average train loss: 0.003212\n",
      "\n",
      "Validating epoch: 54\n",
      "epoch = 54 | i = 0 | valid loss = 0.0000\n",
      "epoch = 54 | i = 500 | valid loss = 0.0000\n",
      "epoch = 54 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051481 | Accuracy: 0.9883 | Recall: 0.9750 | Precision: 0.9898\n",
      "\n",
      "Training epoch: 55. Learning rate: 5.0000e-05\n",
      "epoch = 55 | current step = 16600 | train loss = 0.0658\n",
      "epoch = 55 | current step = 16700 | train loss = 0.0002\n",
      "epoch = 55 | current step = 16800 | train loss = 0.0006\n",
      "Average train loss: 0.006684\n",
      "\n",
      "Validating epoch: 55\n",
      "epoch = 55 | i = 0 | valid loss = 0.0000\n",
      "epoch = 55 | i = 500 | valid loss = 0.0000\n",
      "epoch = 55 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.044733 | Accuracy: 0.9817 | Recall: 0.9850 | Precision: 0.9610\n",
      "\n",
      "Training epoch: 56. Learning rate: 2.5000e-05\n",
      "epoch = 56 | current step = 16900 | train loss = 0.0002\n",
      "epoch = 56 | current step = 17000 | train loss = 0.0000\n",
      "epoch = 56 | current step = 17100 | train loss = 0.0005\n",
      "Average train loss: 0.001644\n",
      "\n",
      "Validating epoch: 56\n",
      "epoch = 56 | i = 0 | valid loss = 0.0000\n",
      "epoch = 56 | i = 500 | valid loss = 0.0000\n",
      "epoch = 56 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.027904 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 57. Learning rate: 2.5000e-05\n",
      "epoch = 57 | current step = 17200 | train loss = 0.0001\n",
      "epoch = 57 | current step = 17300 | train loss = 0.0000\n",
      "epoch = 57 | current step = 17400 | train loss = 0.0000\n",
      "Average train loss: 0.001920\n",
      "\n",
      "Validating epoch: 57\n",
      "epoch = 57 | i = 0 | valid loss = 0.0000\n",
      "epoch = 57 | i = 500 | valid loss = 0.0000\n",
      "epoch = 57 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.031705 | Accuracy: 0.9917 | Recall: 0.9800 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 58. Learning rate: 2.5000e-05\n",
      "epoch = 58 | current step = 17500 | train loss = 0.0282\n",
      "epoch = 58 | current step = 17600 | train loss = 0.0000\n",
      "epoch = 58 | current step = 17700 | train loss = 0.0000\n",
      "Average train loss: 0.000709\n",
      "\n",
      "Validating epoch: 58\n",
      "epoch = 58 | i = 0 | valid loss = 0.0000\n",
      "epoch = 58 | i = 500 | valid loss = 0.0000\n",
      "epoch = 58 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.033383 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 59. Learning rate: 2.5000e-05\n",
      "epoch = 59 | current step = 17800 | train loss = 0.0000\n",
      "epoch = 59 | current step = 17900 | train loss = 0.0000\n",
      "epoch = 59 | current step = 18000 | train loss = 0.0000\n",
      "Average train loss: 0.002273\n",
      "\n",
      "Validating epoch: 59\n",
      "epoch = 59 | i = 0 | valid loss = 0.0000\n",
      "epoch = 59 | i = 500 | valid loss = 0.0000\n",
      "epoch = 59 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.036298 | Accuracy: 0.9925 | Recall: 0.9875 | Precision: 0.9900\n",
      "checkpoint at epoch 060 saved!\n",
      "\n",
      "Training epoch: 60. Learning rate: 2.5000e-05\n",
      "epoch = 60 | current step = 18100 | train loss = 0.0006\n",
      "epoch = 60 | current step = 18200 | train loss = 0.0000\n",
      "epoch = 60 | current step = 18300 | train loss = 0.0001\n",
      "Average train loss: 0.001257\n",
      "\n",
      "Validating epoch: 60\n",
      "epoch = 60 | i = 0 | valid loss = 0.0000\n",
      "epoch = 60 | i = 500 | valid loss = 0.0000\n",
      "epoch = 60 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.029722 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 61. Learning rate: 2.5000e-05\n",
      "epoch = 61 | current step = 18400 | train loss = 0.0000\n",
      "epoch = 61 | current step = 18500 | train loss = 0.0001\n",
      "epoch = 61 | current step = 18600 | train loss = 0.0000\n",
      "Average train loss: 0.000804\n",
      "\n",
      "Validating epoch: 61\n",
      "epoch = 61 | i = 0 | valid loss = 0.0000\n",
      "epoch = 61 | i = 500 | valid loss = 0.0000\n",
      "epoch = 61 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.034859 | Accuracy: 0.9900 | Recall: 0.9875 | Precision: 0.9826\n",
      "\n",
      "Training epoch: 62. Learning rate: 2.5000e-05\n",
      "epoch = 62 | current step = 18700 | train loss = 0.0001\n",
      "epoch = 62 | current step = 18800 | train loss = 0.0001\n",
      "epoch = 62 | current step = 18900 | train loss = 0.0000\n",
      "Average train loss: 0.001306\n",
      "\n",
      "Validating epoch: 62\n",
      "epoch = 62 | i = 0 | valid loss = 0.0000\n",
      "epoch = 62 | i = 500 | valid loss = 0.0000\n",
      "epoch = 62 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.048163 | Accuracy: 0.9892 | Recall: 0.9750 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 63. Learning rate: 2.5000e-05\n",
      "epoch = 63 | current step = 19000 | train loss = 0.0000\n",
      "epoch = 63 | current step = 19100 | train loss = 0.0000\n",
      "epoch = 63 | current step = 19200 | train loss = 0.0000\n",
      "Average train loss: 0.000606\n",
      "\n",
      "Validating epoch: 63\n",
      "epoch = 63 | i = 0 | valid loss = 0.0000\n",
      "epoch = 63 | i = 500 | valid loss = 0.0000\n",
      "epoch = 63 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.044688 | Accuracy: 0.9900 | Recall: 0.9875 | Precision: 0.9826\n",
      "\n",
      "Training epoch: 64. Learning rate: 2.5000e-05\n",
      "epoch = 64 | current step = 19300 | train loss = 0.0000\n",
      "epoch = 64 | current step = 19400 | train loss = 0.0001\n",
      "epoch = 64 | current step = 19500 | train loss = 0.0001\n",
      "Average train loss: 0.000435\n",
      "\n",
      "Validating epoch: 64\n",
      "epoch = 64 | i = 0 | valid loss = 0.0000\n",
      "epoch = 64 | i = 500 | valid loss = 0.0000\n",
      "epoch = 64 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049168 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 65. Learning rate: 2.5000e-05\n",
      "epoch = 65 | current step = 19600 | train loss = 0.0000\n",
      "epoch = 65 | current step = 19700 | train loss = 0.0000\n",
      "epoch = 65 | current step = 19800 | train loss = 0.0000\n",
      "Average train loss: 0.000318\n",
      "\n",
      "Validating epoch: 65\n",
      "epoch = 65 | i = 0 | valid loss = 0.0000\n",
      "epoch = 65 | i = 500 | valid loss = 0.0000\n",
      "epoch = 65 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.050194 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 66. Learning rate: 2.5000e-05\n",
      "epoch = 66 | current step = 19900 | train loss = 0.0005\n",
      "epoch = 66 | current step = 20000 | train loss = 0.0000\n",
      "epoch = 66 | current step = 20100 | train loss = 0.0000\n",
      "Average train loss: 0.000325\n",
      "\n",
      "Validating epoch: 66\n",
      "epoch = 66 | i = 0 | valid loss = 0.0000\n",
      "epoch = 66 | i = 500 | valid loss = 0.0000\n",
      "epoch = 66 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049891 | Accuracy: 0.9933 | Recall: 0.9850 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 67. Learning rate: 1.2500e-05\n",
      "epoch = 67 | current step = 20200 | train loss = 0.0000\n",
      "epoch = 67 | current step = 20300 | train loss = 0.0000\n",
      "epoch = 67 | current step = 20400 | train loss = 0.0101\n",
      "Average train loss: 0.000591\n",
      "\n",
      "Validating epoch: 67\n",
      "epoch = 67 | i = 0 | valid loss = 0.0000\n",
      "epoch = 67 | i = 500 | valid loss = 0.0000\n",
      "epoch = 67 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051415 | Accuracy: 0.9900 | Recall: 0.9775 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 68. Learning rate: 1.2500e-05\n",
      "epoch = 68 | current step = 20500 | train loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 68 | current step = 20600 | train loss = 0.0000\n",
      "epoch = 68 | current step = 20700 | train loss = 0.0000\n",
      "Average train loss: 0.000435\n",
      "\n",
      "Validating epoch: 68\n",
      "epoch = 68 | i = 0 | valid loss = 0.0000\n",
      "epoch = 68 | i = 500 | valid loss = 0.0000\n",
      "epoch = 68 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049642 | Accuracy: 0.9900 | Recall: 0.9775 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 69. Learning rate: 1.2500e-05\n",
      "epoch = 69 | current step = 20800 | train loss = 0.0000\n",
      "epoch = 69 | current step = 20900 | train loss = 0.0000\n",
      "epoch = 69 | current step = 21000 | train loss = 0.0021\n",
      "Average train loss: 0.000322\n",
      "\n",
      "Validating epoch: 69\n",
      "epoch = 69 | i = 0 | valid loss = 0.0000\n",
      "epoch = 69 | i = 500 | valid loss = 0.0000\n",
      "epoch = 69 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051609 | Accuracy: 0.9900 | Recall: 0.9850 | Precision: 0.9850\n",
      "checkpoint at epoch 070 saved!\n",
      "\n",
      "Training epoch: 70. Learning rate: 1.2500e-05\n",
      "epoch = 70 | current step = 21100 | train loss = 0.0000\n",
      "epoch = 70 | current step = 21200 | train loss = 0.0000\n",
      "epoch = 70 | current step = 21300 | train loss = 0.0000\n",
      "Average train loss: 0.000193\n",
      "\n",
      "Validating epoch: 70\n",
      "epoch = 70 | i = 0 | valid loss = 0.0000\n",
      "epoch = 70 | i = 500 | valid loss = 0.0000\n",
      "epoch = 70 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.054145 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 71. Learning rate: 1.2500e-05\n",
      "epoch = 71 | current step = 21400 | train loss = 0.0000\n",
      "epoch = 71 | current step = 21500 | train loss = 0.0002\n",
      "epoch = 71 | current step = 21600 | train loss = 0.0000\n",
      "Average train loss: 0.001070\n",
      "\n",
      "Validating epoch: 71\n",
      "epoch = 71 | i = 0 | valid loss = 0.0000\n",
      "epoch = 71 | i = 500 | valid loss = 0.0000\n",
      "epoch = 71 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051940 | Accuracy: 0.9900 | Recall: 0.9875 | Precision: 0.9826\n",
      "\n",
      "Training epoch: 72. Learning rate: 1.2500e-05\n",
      "epoch = 72 | current step = 21700 | train loss = 0.0000\n",
      "epoch = 72 | current step = 21800 | train loss = 0.0000\n",
      "epoch = 72 | current step = 21900 | train loss = 0.0000\n",
      "Average train loss: 0.000339\n",
      "\n",
      "Validating epoch: 72\n",
      "epoch = 72 | i = 0 | valid loss = 0.0000\n",
      "epoch = 72 | i = 500 | valid loss = 0.0000\n",
      "epoch = 72 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.050526 | Accuracy: 0.9933 | Recall: 0.9875 | Precision: 0.9925\n",
      "\n",
      "Training epoch: 73. Learning rate: 1.2500e-05\n",
      "epoch = 73 | current step = 22000 | train loss = 0.0000\n",
      "epoch = 73 | current step = 22100 | train loss = 0.0000\n",
      "epoch = 73 | current step = 22200 | train loss = 0.0000\n",
      "Average train loss: 0.000711\n",
      "\n",
      "Validating epoch: 73\n",
      "epoch = 73 | i = 0 | valid loss = 0.0000\n",
      "epoch = 73 | i = 500 | valid loss = 0.0000\n",
      "epoch = 73 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049337 | Accuracy: 0.9917 | Recall: 0.9875 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 74. Learning rate: 1.2500e-05\n",
      "epoch = 74 | current step = 22300 | train loss = 0.0000\n",
      "epoch = 74 | current step = 22400 | train loss = 0.0000\n",
      "epoch = 74 | current step = 22500 | train loss = 0.0000\n",
      "Average train loss: 0.000262\n",
      "\n",
      "Validating epoch: 74\n",
      "epoch = 74 | i = 0 | valid loss = 0.0000\n",
      "epoch = 74 | i = 500 | valid loss = 0.0000\n",
      "epoch = 74 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.050863 | Accuracy: 0.9925 | Recall: 0.9875 | Precision: 0.9900\n",
      "\n",
      "Training epoch: 75. Learning rate: 1.2500e-05\n",
      "epoch = 75 | current step = 22600 | train loss = 0.0014\n",
      "epoch = 75 | current step = 22700 | train loss = 0.0000\n",
      "epoch = 75 | current step = 22800 | train loss = 0.0021\n",
      "Average train loss: 0.000207\n",
      "\n",
      "Validating epoch: 75\n",
      "epoch = 75 | i = 0 | valid loss = 0.0000\n",
      "epoch = 75 | i = 500 | valid loss = 0.0000\n",
      "epoch = 75 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.050030 | Accuracy: 0.9942 | Recall: 0.9875 | Precision: 0.9950\n",
      "\n",
      "Training epoch: 76. Learning rate: 1.2500e-05\n",
      "epoch = 76 | current step = 22900 | train loss = 0.0000\n",
      "epoch = 76 | current step = 23000 | train loss = 0.0001\n",
      "epoch = 76 | current step = 23100 | train loss = 0.0000\n",
      "Average train loss: 0.001931\n",
      "\n",
      "Validating epoch: 76\n",
      "epoch = 76 | i = 0 | valid loss = 0.0000\n",
      "epoch = 76 | i = 500 | valid loss = 0.0000\n",
      "epoch = 76 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053134 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 77. Learning rate: 1.2500e-05\n",
      "epoch = 77 | current step = 23200 | train loss = 0.0000\n",
      "epoch = 77 | current step = 23300 | train loss = 0.0000\n",
      "epoch = 77 | current step = 23400 | train loss = 0.0000\n",
      "Average train loss: 0.000552\n",
      "\n",
      "Validating epoch: 77\n",
      "epoch = 77 | i = 0 | valid loss = 0.0000\n",
      "epoch = 77 | i = 500 | valid loss = 0.0000\n",
      "epoch = 77 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051294 | Accuracy: 0.9875 | Recall: 0.9850 | Precision: 0.9777\n",
      "\n",
      "Training epoch: 78. Learning rate: 6.2500e-06\n",
      "epoch = 78 | current step = 23500 | train loss = 0.0002\n",
      "epoch = 78 | current step = 23600 | train loss = 0.0000\n",
      "epoch = 78 | current step = 23700 | train loss = 0.0002\n",
      "Average train loss: 0.001201\n",
      "\n",
      "Validating epoch: 78\n",
      "epoch = 78 | i = 0 | valid loss = 0.0000\n",
      "epoch = 78 | i = 500 | valid loss = 0.0000\n",
      "epoch = 78 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051729 | Accuracy: 0.9908 | Recall: 0.9775 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 79. Learning rate: 6.2500e-06\n",
      "epoch = 79 | current step = 23800 | train loss = 0.0000\n",
      "epoch = 79 | current step = 23900 | train loss = 0.0000\n",
      "epoch = 79 | current step = 24000 | train loss = 0.0000\n",
      "Average train loss: 0.000143\n",
      "\n",
      "Validating epoch: 79\n",
      "epoch = 79 | i = 0 | valid loss = 0.0000\n",
      "epoch = 79 | i = 500 | valid loss = 0.0000\n",
      "epoch = 79 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.046101 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "checkpoint at epoch 080 saved!\n",
      "\n",
      "Training epoch: 80. Learning rate: 6.2500e-06\n",
      "epoch = 80 | current step = 24100 | train loss = 0.0000\n",
      "epoch = 80 | current step = 24200 | train loss = 0.0001\n",
      "epoch = 80 | current step = 24300 | train loss = 0.0000\n",
      "Average train loss: 0.000224\n",
      "\n",
      "Validating epoch: 80\n",
      "epoch = 80 | i = 0 | valid loss = 0.0000\n",
      "epoch = 80 | i = 500 | valid loss = 0.0000\n",
      "epoch = 80 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.044067 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 81. Learning rate: 6.2500e-06\n",
      "epoch = 81 | current step = 24400 | train loss = 0.0000\n",
      "epoch = 81 | current step = 24500 | train loss = 0.0000\n",
      "epoch = 81 | current step = 24600 | train loss = 0.0000\n",
      "Average train loss: 0.000343\n",
      "\n",
      "Validating epoch: 81\n",
      "epoch = 81 | i = 0 | valid loss = 0.0000\n",
      "epoch = 81 | i = 500 | valid loss = 0.0000\n",
      "epoch = 81 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.046141 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 82. Learning rate: 6.2500e-06\n",
      "epoch = 82 | current step = 24700 | train loss = 0.0000\n",
      "epoch = 82 | current step = 24800 | train loss = 0.0000\n",
      "epoch = 82 | current step = 24900 | train loss = 0.0000\n",
      "Average train loss: 0.000144\n",
      "\n",
      "Validating epoch: 82\n",
      "epoch = 82 | i = 0 | valid loss = 0.0000\n",
      "epoch = 82 | i = 500 | valid loss = 0.0000\n",
      "epoch = 82 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.044173 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 83. Learning rate: 6.2500e-06\n",
      "epoch = 83 | current step = 25000 | train loss = 0.0000\n",
      "epoch = 83 | current step = 25100 | train loss = 0.0000\n",
      "epoch = 83 | current step = 25200 | train loss = 0.0000\n",
      "Average train loss: 0.000317\n",
      "\n",
      "Validating epoch: 83\n",
      "epoch = 83 | i = 0 | valid loss = 0.0000\n",
      "epoch = 83 | i = 500 | valid loss = 0.0000\n",
      "epoch = 83 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.047833 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 84. Learning rate: 6.2500e-06\n",
      "epoch = 84 | current step = 25300 | train loss = 0.0000\n",
      "epoch = 84 | current step = 25400 | train loss = 0.0005\n",
      "epoch = 84 | current step = 25500 | train loss = 0.0000\n",
      "Average train loss: 0.000316\n",
      "\n",
      "Validating epoch: 84\n",
      "epoch = 84 | i = 0 | valid loss = 0.0000\n",
      "epoch = 84 | i = 500 | valid loss = 0.0000\n",
      "epoch = 84 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049487 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 85. Learning rate: 6.2500e-06\n",
      "epoch = 85 | current step = 25600 | train loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 85 | current step = 25700 | train loss = 0.0000\n",
      "epoch = 85 | current step = 25800 | train loss = 0.0000\n",
      "Average train loss: 0.000047\n",
      "\n",
      "Validating epoch: 85\n",
      "epoch = 85 | i = 0 | valid loss = 0.0000\n",
      "epoch = 85 | i = 500 | valid loss = 0.0000\n",
      "epoch = 85 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.048405 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 86. Learning rate: 6.2500e-06\n",
      "epoch = 86 | current step = 25900 | train loss = 0.0000\n",
      "epoch = 86 | current step = 26000 | train loss = 0.0000\n",
      "epoch = 86 | current step = 26100 | train loss = 0.0001\n",
      "Average train loss: 0.000044\n",
      "\n",
      "Validating epoch: 86\n",
      "epoch = 86 | i = 0 | valid loss = 0.0000\n",
      "epoch = 86 | i = 500 | valid loss = 0.0000\n",
      "epoch = 86 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.049528 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 87. Learning rate: 6.2500e-06\n",
      "epoch = 87 | current step = 26200 | train loss = 0.0002\n",
      "epoch = 87 | current step = 26300 | train loss = 0.0000\n",
      "epoch = 87 | current step = 26400 | train loss = 0.0000\n",
      "Average train loss: 0.000077\n",
      "\n",
      "Validating epoch: 87\n",
      "epoch = 87 | i = 0 | valid loss = 0.0000\n",
      "epoch = 87 | i = 500 | valid loss = 0.0000\n",
      "epoch = 87 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.050362 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 88. Learning rate: 6.2500e-06\n",
      "epoch = 88 | current step = 26500 | train loss = 0.0000\n",
      "epoch = 88 | current step = 26600 | train loss = 0.0001\n",
      "epoch = 88 | current step = 26700 | train loss = 0.0001\n",
      "Average train loss: 0.000058\n",
      "\n",
      "Validating epoch: 88\n",
      "epoch = 88 | i = 0 | valid loss = 0.0000\n",
      "epoch = 88 | i = 500 | valid loss = 0.0000\n",
      "epoch = 88 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053307 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 89. Learning rate: 3.1250e-06\n",
      "epoch = 89 | current step = 26800 | train loss = 0.0000\n",
      "epoch = 89 | current step = 26900 | train loss = 0.0000\n",
      "epoch = 89 | current step = 27000 | train loss = 0.0000\n",
      "Average train loss: 0.000054\n",
      "\n",
      "Validating epoch: 89\n",
      "epoch = 89 | i = 0 | valid loss = 0.0000\n",
      "epoch = 89 | i = 500 | valid loss = 0.0000\n",
      "epoch = 89 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052866 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "checkpoint at epoch 090 saved!\n",
      "\n",
      "Training epoch: 90. Learning rate: 3.1250e-06\n",
      "epoch = 90 | current step = 27100 | train loss = 0.0000\n",
      "epoch = 90 | current step = 27200 | train loss = 0.0000\n",
      "epoch = 90 | current step = 27300 | train loss = 0.0000\n",
      "Average train loss: 0.000093\n",
      "\n",
      "Validating epoch: 90\n",
      "epoch = 90 | i = 0 | valid loss = 0.0000\n",
      "epoch = 90 | i = 500 | valid loss = 0.0000\n",
      "epoch = 90 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052717 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 91. Learning rate: 3.1250e-06\n",
      "epoch = 91 | current step = 27400 | train loss = 0.0000\n",
      "epoch = 91 | current step = 27500 | train loss = 0.0000\n",
      "epoch = 91 | current step = 27600 | train loss = 0.0002\n",
      "Average train loss: 0.000092\n",
      "\n",
      "Validating epoch: 91\n",
      "epoch = 91 | i = 0 | valid loss = 0.0000\n",
      "epoch = 91 | i = 500 | valid loss = 0.0000\n",
      "epoch = 91 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051390 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 92. Learning rate: 3.1250e-06\n",
      "epoch = 92 | current step = 27700 | train loss = 0.0000\n",
      "epoch = 92 | current step = 27800 | train loss = 0.0000\n",
      "epoch = 92 | current step = 27900 | train loss = 0.0006\n",
      "Average train loss: 0.000026\n",
      "\n",
      "Validating epoch: 92\n",
      "epoch = 92 | i = 0 | valid loss = 0.0000\n",
      "epoch = 92 | i = 500 | valid loss = 0.0000\n",
      "epoch = 92 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.047371 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 93. Learning rate: 3.1250e-06\n",
      "epoch = 93 | current step = 28000 | train loss = 0.0000\n",
      "epoch = 93 | current step = 28100 | train loss = 0.0000\n",
      "epoch = 93 | current step = 28200 | train loss = 0.0000\n",
      "Average train loss: 0.000035\n",
      "\n",
      "Validating epoch: 93\n",
      "epoch = 93 | i = 0 | valid loss = 0.0000\n",
      "epoch = 93 | i = 500 | valid loss = 0.0000\n",
      "epoch = 93 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052144 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 94. Learning rate: 3.1250e-06\n",
      "epoch = 94 | current step = 28300 | train loss = 0.0000\n",
      "epoch = 94 | current step = 28400 | train loss = 0.0000\n",
      "epoch = 94 | current step = 28500 | train loss = 0.0000\n",
      "Average train loss: 0.000034\n",
      "\n",
      "Validating epoch: 94\n",
      "epoch = 94 | i = 0 | valid loss = 0.0000\n",
      "epoch = 94 | i = 500 | valid loss = 0.0000\n",
      "epoch = 94 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052749 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 95. Learning rate: 3.1250e-06\n",
      "epoch = 95 | current step = 28600 | train loss = 0.0000\n",
      "epoch = 95 | current step = 28700 | train loss = 0.0000\n",
      "epoch = 95 | current step = 28800 | train loss = 0.0000\n",
      "Average train loss: 0.000058\n",
      "\n",
      "Validating epoch: 95\n",
      "epoch = 95 | i = 0 | valid loss = 0.0000\n",
      "epoch = 95 | i = 500 | valid loss = 0.0000\n",
      "epoch = 95 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.051293 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 96. Learning rate: 3.1250e-06\n",
      "epoch = 96 | current step = 28900 | train loss = 0.0000\n",
      "epoch = 96 | current step = 29000 | train loss = 0.0000\n",
      "epoch = 96 | current step = 29100 | train loss = 0.0000\n",
      "Average train loss: 0.000365\n",
      "\n",
      "Validating epoch: 96\n",
      "epoch = 96 | i = 0 | valid loss = 0.0000\n",
      "epoch = 96 | i = 500 | valid loss = 0.0000\n",
      "epoch = 96 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.055991 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 97. Learning rate: 3.1250e-06\n",
      "epoch = 97 | current step = 29200 | train loss = 0.0000\n",
      "epoch = 97 | current step = 29300 | train loss = 0.0000\n",
      "epoch = 97 | current step = 29400 | train loss = 0.0000\n",
      "Average train loss: 0.000146\n",
      "\n",
      "Validating epoch: 97\n",
      "epoch = 97 | i = 0 | valid loss = 0.0000\n",
      "epoch = 97 | i = 500 | valid loss = 0.0000\n",
      "epoch = 97 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057426 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 98. Learning rate: 3.1250e-06\n",
      "epoch = 98 | current step = 29500 | train loss = 0.0000\n",
      "epoch = 98 | current step = 29600 | train loss = 0.0000\n",
      "epoch = 98 | current step = 29700 | train loss = 0.0000\n",
      "Average train loss: 0.000035\n",
      "\n",
      "Validating epoch: 98\n",
      "epoch = 98 | i = 0 | valid loss = 0.0000\n",
      "epoch = 98 | i = 500 | valid loss = 0.0000\n",
      "epoch = 98 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053801 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 99. Learning rate: 3.1250e-06\n",
      "epoch = 99 | current step = 29800 | train loss = 0.0000\n",
      "epoch = 99 | current step = 29900 | train loss = 0.0000\n",
      "epoch = 99 | current step = 30000 | train loss = 0.0000\n",
      "Average train loss: 0.000035\n",
      "\n",
      "Validating epoch: 99\n",
      "epoch = 99 | i = 0 | valid loss = 0.0000\n",
      "epoch = 99 | i = 500 | valid loss = 0.0000\n",
      "epoch = 99 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059127 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "checkpoint at epoch 100 saved!\n",
      "\n",
      "Training epoch: 100. Learning rate: 1.5625e-06\n",
      "epoch = 100 | current step = 30100 | train loss = 0.0000\n",
      "epoch = 100 | current step = 30200 | train loss = 0.0000\n",
      "epoch = 100 | current step = 30300 | train loss = 0.0000\n",
      "Average train loss: 0.000030\n",
      "\n",
      "Validating epoch: 100\n",
      "epoch = 100 | i = 0 | valid loss = 0.0000\n",
      "epoch = 100 | i = 500 | valid loss = 0.0000\n",
      "epoch = 100 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058294 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 101. Learning rate: 1.5625e-06\n",
      "epoch = 101 | current step = 30400 | train loss = 0.0000\n",
      "epoch = 101 | current step = 30500 | train loss = 0.0000\n",
      "epoch = 101 | current step = 30600 | train loss = 0.0000\n",
      "Average train loss: 0.000310\n",
      "\n",
      "Validating epoch: 101\n",
      "epoch = 101 | i = 0 | valid loss = 0.0000\n",
      "epoch = 101 | i = 500 | valid loss = 0.0000\n",
      "epoch = 101 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060565 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 102. Learning rate: 1.5625e-06\n",
      "epoch = 102 | current step = 30700 | train loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 102 | current step = 30800 | train loss = 0.0000\n",
      "epoch = 102 | current step = 30900 | train loss = 0.0000\n",
      "Average train loss: 0.000031\n",
      "\n",
      "Validating epoch: 102\n",
      "epoch = 102 | i = 0 | valid loss = 0.0000\n",
      "epoch = 102 | i = 500 | valid loss = 0.0000\n",
      "epoch = 102 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056371 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 103. Learning rate: 1.5625e-06\n",
      "epoch = 103 | current step = 31000 | train loss = 0.0000\n",
      "epoch = 103 | current step = 31100 | train loss = 0.0000\n",
      "epoch = 103 | current step = 31200 | train loss = 0.0000\n",
      "Average train loss: 0.000192\n",
      "\n",
      "Validating epoch: 103\n",
      "epoch = 103 | i = 0 | valid loss = 0.0000\n",
      "epoch = 103 | i = 500 | valid loss = 0.0000\n",
      "epoch = 103 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056583 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 104. Learning rate: 1.5625e-06\n",
      "epoch = 104 | current step = 31300 | train loss = 0.0000\n",
      "epoch = 104 | current step = 31400 | train loss = 0.0000\n",
      "epoch = 104 | current step = 31500 | train loss = 0.0000\n",
      "Average train loss: 0.000018\n",
      "\n",
      "Validating epoch: 104\n",
      "epoch = 104 | i = 0 | valid loss = 0.0000\n",
      "epoch = 104 | i = 500 | valid loss = 0.0000\n",
      "epoch = 104 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056340 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 105. Learning rate: 1.5625e-06\n",
      "epoch = 105 | current step = 31600 | train loss = 0.0000\n",
      "epoch = 105 | current step = 31700 | train loss = 0.0000\n",
      "epoch = 105 | current step = 31800 | train loss = 0.0000\n",
      "Average train loss: 0.000018\n",
      "\n",
      "Validating epoch: 105\n",
      "epoch = 105 | i = 0 | valid loss = 0.0000\n",
      "epoch = 105 | i = 500 | valid loss = 0.0000\n",
      "epoch = 105 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056757 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 106. Learning rate: 1.5625e-06\n",
      "epoch = 106 | current step = 31900 | train loss = 0.0000\n",
      "epoch = 106 | current step = 32000 | train loss = 0.0000\n",
      "epoch = 106 | current step = 32100 | train loss = 0.0000\n",
      "Average train loss: 0.000028\n",
      "\n",
      "Validating epoch: 106\n",
      "epoch = 106 | i = 0 | valid loss = 0.0000\n",
      "epoch = 106 | i = 500 | valid loss = 0.0000\n",
      "epoch = 106 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060112 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 107. Learning rate: 1.5625e-06\n",
      "epoch = 107 | current step = 32200 | train loss = 0.0000\n",
      "epoch = 107 | current step = 32300 | train loss = 0.0000\n",
      "epoch = 107 | current step = 32400 | train loss = 0.0000\n",
      "Average train loss: 0.000684\n",
      "\n",
      "Validating epoch: 107\n",
      "epoch = 107 | i = 0 | valid loss = 0.0000\n",
      "epoch = 107 | i = 500 | valid loss = 0.0000\n",
      "epoch = 107 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052873 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 108. Learning rate: 1.5625e-06\n",
      "epoch = 108 | current step = 32500 | train loss = 0.0000\n",
      "epoch = 108 | current step = 32600 | train loss = 0.0000\n",
      "epoch = 108 | current step = 32700 | train loss = 0.0000\n",
      "Average train loss: 0.000056\n",
      "\n",
      "Validating epoch: 108\n",
      "epoch = 108 | i = 0 | valid loss = 0.0000\n",
      "epoch = 108 | i = 500 | valid loss = 0.0000\n",
      "epoch = 108 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052689 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 109. Learning rate: 1.5625e-06\n",
      "epoch = 109 | current step = 32800 | train loss = 0.0000\n",
      "epoch = 109 | current step = 32900 | train loss = 0.0000\n",
      "epoch = 109 | current step = 33000 | train loss = 0.0000\n",
      "Average train loss: 0.000054\n",
      "\n",
      "Validating epoch: 109\n",
      "epoch = 109 | i = 0 | valid loss = 0.0000\n",
      "epoch = 109 | i = 500 | valid loss = 0.0000\n",
      "epoch = 109 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.052071 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "checkpoint at epoch 110 saved!\n",
      "\n",
      "Training epoch: 110. Learning rate: 1.5625e-06\n",
      "epoch = 110 | current step = 33100 | train loss = 0.0000\n",
      "epoch = 110 | current step = 33200 | train loss = 0.0000\n",
      "epoch = 110 | current step = 33300 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 110\n",
      "epoch = 110 | i = 0 | valid loss = 0.0000\n",
      "epoch = 110 | i = 500 | valid loss = 0.0000\n",
      "epoch = 110 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060174 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 111. Learning rate: 1.0000e-06\n",
      "epoch = 111 | current step = 33400 | train loss = 0.0000\n",
      "epoch = 111 | current step = 33500 | train loss = 0.0000\n",
      "epoch = 111 | current step = 33600 | train loss = 0.0000\n",
      "Average train loss: 0.000194\n",
      "\n",
      "Validating epoch: 111\n",
      "epoch = 111 | i = 0 | valid loss = 0.0000\n",
      "epoch = 111 | i = 500 | valid loss = 0.0000\n",
      "epoch = 111 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056016 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 112. Learning rate: 1.0000e-06\n",
      "epoch = 112 | current step = 33700 | train loss = 0.0000\n",
      "epoch = 112 | current step = 33800 | train loss = 0.0000\n",
      "epoch = 112 | current step = 33900 | train loss = 0.0000\n",
      "Average train loss: 0.000017\n",
      "\n",
      "Validating epoch: 112\n",
      "epoch = 112 | i = 0 | valid loss = 0.0000\n",
      "epoch = 112 | i = 500 | valid loss = 0.0000\n",
      "epoch = 112 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057660 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 113. Learning rate: 1.0000e-06\n",
      "epoch = 113 | current step = 34000 | train loss = 0.0000\n",
      "epoch = 113 | current step = 34100 | train loss = 0.0000\n",
      "epoch = 113 | current step = 34200 | train loss = 0.0000\n",
      "Average train loss: 0.000024\n",
      "\n",
      "Validating epoch: 113\n",
      "epoch = 113 | i = 0 | valid loss = 0.0000\n",
      "epoch = 113 | i = 500 | valid loss = 0.0000\n",
      "epoch = 113 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053807 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 114. Learning rate: 1.0000e-06\n",
      "epoch = 114 | current step = 34300 | train loss = 0.0000\n",
      "epoch = 114 | current step = 34400 | train loss = 0.0000\n",
      "epoch = 114 | current step = 34500 | train loss = 0.0000\n",
      "Average train loss: 0.000014\n",
      "\n",
      "Validating epoch: 114\n",
      "epoch = 114 | i = 0 | valid loss = 0.0000\n",
      "epoch = 114 | i = 500 | valid loss = 0.0000\n",
      "epoch = 114 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058148 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 115. Learning rate: 1.0000e-06\n",
      "epoch = 115 | current step = 34600 | train loss = 0.0000\n",
      "epoch = 115 | current step = 34700 | train loss = 0.0000\n",
      "epoch = 115 | current step = 34800 | train loss = 0.0000\n",
      "Average train loss: 0.000019\n",
      "\n",
      "Validating epoch: 115\n",
      "epoch = 115 | i = 0 | valid loss = 0.0000\n",
      "epoch = 115 | i = 500 | valid loss = 0.0000\n",
      "epoch = 115 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053937 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 116. Learning rate: 1.0000e-06\n",
      "epoch = 116 | current step = 34900 | train loss = 0.0000\n",
      "epoch = 116 | current step = 35000 | train loss = 0.0000\n",
      "epoch = 116 | current step = 35100 | train loss = 0.0000\n",
      "Average train loss: 0.000184\n",
      "\n",
      "Validating epoch: 116\n",
      "epoch = 116 | i = 0 | valid loss = 0.0000\n",
      "epoch = 116 | i = 500 | valid loss = 0.0000\n",
      "epoch = 116 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.054960 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 117. Learning rate: 1.0000e-06\n",
      "epoch = 117 | current step = 35200 | train loss = 0.0000\n",
      "epoch = 117 | current step = 35300 | train loss = 0.0000\n",
      "epoch = 117 | current step = 35400 | train loss = 0.0000\n",
      "Average train loss: 0.000254\n",
      "\n",
      "Validating epoch: 117\n",
      "epoch = 117 | i = 0 | valid loss = 0.0000\n",
      "epoch = 117 | i = 500 | valid loss = 0.0000\n",
      "epoch = 117 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060468 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 118. Learning rate: 1.0000e-06\n",
      "epoch = 118 | current step = 35500 | train loss = 0.0002\n",
      "epoch = 118 | current step = 35600 | train loss = 0.0000\n",
      "epoch = 118 | current step = 35700 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 118\n",
      "epoch = 118 | i = 0 | valid loss = 0.0000\n",
      "epoch = 118 | i = 500 | valid loss = 0.0000\n",
      "epoch = 118 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057048 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 119. Learning rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 119 | current step = 35800 | train loss = 0.0001\n",
      "epoch = 119 | current step = 35900 | train loss = 0.0000\n",
      "epoch = 119 | current step = 36000 | train loss = 0.0000\n",
      "Average train loss: 0.000033\n",
      "\n",
      "Validating epoch: 119\n",
      "epoch = 119 | i = 0 | valid loss = 0.0000\n",
      "epoch = 119 | i = 500 | valid loss = 0.0000\n",
      "epoch = 119 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057899 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "checkpoint at epoch 120 saved!\n",
      "\n",
      "Training epoch: 120. Learning rate: 1.0000e-06\n",
      "epoch = 120 | current step = 36100 | train loss = 0.0000\n",
      "epoch = 120 | current step = 36200 | train loss = 0.0000\n",
      "epoch = 120 | current step = 36300 | train loss = 0.0000\n",
      "Average train loss: 0.000017\n",
      "\n",
      "Validating epoch: 120\n",
      "epoch = 120 | i = 0 | valid loss = 0.0000\n",
      "epoch = 120 | i = 500 | valid loss = 0.0000\n",
      "epoch = 120 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053695 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 121. Learning rate: 1.0000e-06\n",
      "epoch = 121 | current step = 36400 | train loss = 0.0011\n",
      "epoch = 121 | current step = 36500 | train loss = 0.0001\n",
      "epoch = 121 | current step = 36600 | train loss = 0.0000\n",
      "Average train loss: 0.000028\n",
      "\n",
      "Validating epoch: 121\n",
      "epoch = 121 | i = 0 | valid loss = 0.0000\n",
      "epoch = 121 | i = 500 | valid loss = 0.0000\n",
      "epoch = 121 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059330 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 122. Learning rate: 1.0000e-06\n",
      "epoch = 122 | current step = 36700 | train loss = 0.0000\n",
      "epoch = 122 | current step = 36800 | train loss = 0.0000\n",
      "epoch = 122 | current step = 36900 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 122\n",
      "epoch = 122 | i = 0 | valid loss = 0.0000\n",
      "epoch = 122 | i = 500 | valid loss = 0.0000\n",
      "epoch = 122 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.055320 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 123. Learning rate: 1.0000e-06\n",
      "epoch = 123 | current step = 37000 | train loss = 0.0000\n",
      "epoch = 123 | current step = 37100 | train loss = 0.0000\n",
      "epoch = 123 | current step = 37200 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 123\n",
      "epoch = 123 | i = 0 | valid loss = 0.0000\n",
      "epoch = 123 | i = 500 | valid loss = 0.0000\n",
      "epoch = 123 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058382 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 124. Learning rate: 1.0000e-06\n",
      "epoch = 124 | current step = 37300 | train loss = 0.0000\n",
      "epoch = 124 | current step = 37400 | train loss = 0.0000\n",
      "epoch = 124 | current step = 37500 | train loss = 0.0000\n",
      "Average train loss: 0.000023\n",
      "\n",
      "Validating epoch: 124\n",
      "epoch = 124 | i = 0 | valid loss = 0.0000\n",
      "epoch = 124 | i = 500 | valid loss = 0.0000\n",
      "epoch = 124 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059242 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 125. Learning rate: 1.0000e-06\n",
      "epoch = 125 | current step = 37600 | train loss = 0.0000\n",
      "epoch = 125 | current step = 37700 | train loss = 0.0000\n",
      "epoch = 125 | current step = 37800 | train loss = 0.0000\n",
      "Average train loss: 0.000187\n",
      "\n",
      "Validating epoch: 125\n",
      "epoch = 125 | i = 0 | valid loss = 0.0000\n",
      "epoch = 125 | i = 500 | valid loss = 0.0000\n",
      "epoch = 125 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.053802 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 126. Learning rate: 1.0000e-06\n",
      "epoch = 126 | current step = 37900 | train loss = 0.0000\n",
      "epoch = 126 | current step = 38000 | train loss = 0.0000\n",
      "epoch = 126 | current step = 38100 | train loss = 0.0000\n",
      "Average train loss: 0.000019\n",
      "\n",
      "Validating epoch: 126\n",
      "epoch = 126 | i = 0 | valid loss = 0.0000\n",
      "epoch = 126 | i = 500 | valid loss = 0.0000\n",
      "epoch = 126 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058166 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 127. Learning rate: 1.0000e-06\n",
      "epoch = 127 | current step = 38200 | train loss = 0.0000\n",
      "epoch = 127 | current step = 38300 | train loss = 0.0000\n",
      "epoch = 127 | current step = 38400 | train loss = 0.0000\n",
      "Average train loss: 0.000168\n",
      "\n",
      "Validating epoch: 127\n",
      "epoch = 127 | i = 0 | valid loss = 0.0000\n",
      "epoch = 127 | i = 500 | valid loss = 0.0000\n",
      "epoch = 127 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057718 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 128. Learning rate: 1.0000e-06\n",
      "epoch = 128 | current step = 38500 | train loss = 0.0000\n",
      "epoch = 128 | current step = 38600 | train loss = 0.0000\n",
      "epoch = 128 | current step = 38700 | train loss = 0.0000\n",
      "Average train loss: 0.000016\n",
      "\n",
      "Validating epoch: 128\n",
      "epoch = 128 | i = 0 | valid loss = 0.0000\n",
      "epoch = 128 | i = 500 | valid loss = 0.0000\n",
      "epoch = 128 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059966 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 129. Learning rate: 1.0000e-06\n",
      "epoch = 129 | current step = 38800 | train loss = 0.0000\n",
      "epoch = 129 | current step = 38900 | train loss = 0.0000\n",
      "epoch = 129 | current step = 39000 | train loss = 0.0000\n",
      "Average train loss: 0.000030\n",
      "\n",
      "Validating epoch: 129\n",
      "epoch = 129 | i = 0 | valid loss = 0.0000\n",
      "epoch = 129 | i = 500 | valid loss = 0.0000\n",
      "epoch = 129 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059429 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "checkpoint at epoch 130 saved!\n",
      "\n",
      "Training epoch: 130. Learning rate: 1.0000e-06\n",
      "epoch = 130 | current step = 39100 | train loss = 0.0000\n",
      "epoch = 130 | current step = 39200 | train loss = 0.0000\n",
      "epoch = 130 | current step = 39300 | train loss = 0.0000\n",
      "Average train loss: 0.000020\n",
      "\n",
      "Validating epoch: 130\n",
      "epoch = 130 | i = 0 | valid loss = 0.0000\n",
      "epoch = 130 | i = 500 | valid loss = 0.0000\n",
      "epoch = 130 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060110 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 131. Learning rate: 1.0000e-06\n",
      "epoch = 131 | current step = 39400 | train loss = 0.0000\n",
      "epoch = 131 | current step = 39500 | train loss = 0.0000\n",
      "epoch = 131 | current step = 39600 | train loss = 0.0000\n",
      "Average train loss: 0.000012\n",
      "\n",
      "Validating epoch: 131\n",
      "epoch = 131 | i = 0 | valid loss = 0.0000\n",
      "epoch = 131 | i = 500 | valid loss = 0.0000\n",
      "epoch = 131 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056464 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 132. Learning rate: 1.0000e-06\n",
      "epoch = 132 | current step = 39700 | train loss = 0.0000\n",
      "epoch = 132 | current step = 39800 | train loss = 0.0000\n",
      "epoch = 132 | current step = 39900 | train loss = 0.0000\n",
      "Average train loss: 0.000013\n",
      "\n",
      "Validating epoch: 132\n",
      "epoch = 132 | i = 0 | valid loss = 0.0000\n",
      "epoch = 132 | i = 500 | valid loss = 0.0000\n",
      "epoch = 132 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058297 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 133. Learning rate: 1.0000e-06\n",
      "epoch = 133 | current step = 40000 | train loss = 0.0000\n",
      "epoch = 133 | current step = 40100 | train loss = 0.0000\n",
      "epoch = 133 | current step = 40200 | train loss = 0.0000\n",
      "Average train loss: 0.000015\n",
      "\n",
      "Validating epoch: 133\n",
      "epoch = 133 | i = 0 | valid loss = 0.0000\n",
      "epoch = 133 | i = 500 | valid loss = 0.0000\n",
      "epoch = 133 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061517 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 134. Learning rate: 1.0000e-06\n",
      "epoch = 134 | current step = 40300 | train loss = 0.0000\n",
      "epoch = 134 | current step = 40400 | train loss = 0.0000\n",
      "epoch = 134 | current step = 40500 | train loss = 0.0000\n",
      "Average train loss: 0.000014\n",
      "\n",
      "Validating epoch: 134\n",
      "epoch = 134 | i = 0 | valid loss = 0.0000\n",
      "epoch = 134 | i = 500 | valid loss = 0.0000\n",
      "epoch = 134 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.056054 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 135. Learning rate: 1.0000e-06\n",
      "epoch = 135 | current step = 40600 | train loss = 0.0001\n",
      "epoch = 135 | current step = 40700 | train loss = 0.0000\n",
      "epoch = 135 | current step = 40800 | train loss = 0.0000\n",
      "Average train loss: 0.000014\n",
      "\n",
      "Validating epoch: 135\n",
      "epoch = 135 | i = 0 | valid loss = 0.0000\n",
      "epoch = 135 | i = 500 | valid loss = 0.0000\n",
      "epoch = 135 | i = 1000 | valid loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average valid loss: 0.061692 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 136. Learning rate: 1.0000e-06\n",
      "epoch = 136 | current step = 40900 | train loss = 0.0000\n",
      "epoch = 136 | current step = 41000 | train loss = 0.0000\n",
      "epoch = 136 | current step = 41100 | train loss = 0.0000\n",
      "Average train loss: 0.000012\n",
      "\n",
      "Validating epoch: 136\n",
      "epoch = 136 | i = 0 | valid loss = 0.0000\n",
      "epoch = 136 | i = 500 | valid loss = 0.0000\n",
      "epoch = 136 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057278 | Accuracy: 0.9892 | Recall: 0.9800 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 137. Learning rate: 1.0000e-06\n",
      "epoch = 137 | current step = 41200 | train loss = 0.0000\n",
      "epoch = 137 | current step = 41300 | train loss = 0.0000\n",
      "epoch = 137 | current step = 41400 | train loss = 0.0000\n",
      "Average train loss: 0.000041\n",
      "\n",
      "Validating epoch: 137\n",
      "epoch = 137 | i = 0 | valid loss = 0.0000\n",
      "epoch = 137 | i = 500 | valid loss = 0.0000\n",
      "epoch = 137 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062563 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 138. Learning rate: 1.0000e-06\n",
      "epoch = 138 | current step = 41500 | train loss = 0.0000\n",
      "epoch = 138 | current step = 41600 | train loss = 0.0085\n",
      "epoch = 138 | current step = 41700 | train loss = 0.0000\n",
      "Average train loss: 0.000041\n",
      "\n",
      "Validating epoch: 138\n",
      "epoch = 138 | i = 0 | valid loss = 0.0000\n",
      "epoch = 138 | i = 500 | valid loss = 0.0000\n",
      "epoch = 138 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061976 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 139. Learning rate: 1.0000e-06\n",
      "epoch = 139 | current step = 41800 | train loss = 0.0000\n",
      "epoch = 139 | current step = 41900 | train loss = 0.0000\n",
      "epoch = 139 | current step = 42000 | train loss = 0.0000\n",
      "Average train loss: 0.000028\n",
      "\n",
      "Validating epoch: 139\n",
      "epoch = 139 | i = 0 | valid loss = 0.0000\n",
      "epoch = 139 | i = 500 | valid loss = 0.0000\n",
      "epoch = 139 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061442 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "checkpoint at epoch 140 saved!\n",
      "\n",
      "Training epoch: 140. Learning rate: 1.0000e-06\n",
      "epoch = 140 | current step = 42100 | train loss = 0.0000\n",
      "epoch = 140 | current step = 42200 | train loss = 0.0000\n",
      "epoch = 140 | current step = 42300 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 140\n",
      "epoch = 140 | i = 0 | valid loss = 0.0000\n",
      "epoch = 140 | i = 500 | valid loss = 0.0000\n",
      "epoch = 140 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058654 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 141. Learning rate: 1.0000e-06\n",
      "epoch = 141 | current step = 42400 | train loss = 0.0000\n",
      "epoch = 141 | current step = 42500 | train loss = 0.0000\n",
      "epoch = 141 | current step = 42600 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 141\n",
      "epoch = 141 | i = 0 | valid loss = 0.0000\n",
      "epoch = 141 | i = 500 | valid loss = 0.0000\n",
      "epoch = 141 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057405 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 142. Learning rate: 1.0000e-06\n",
      "epoch = 142 | current step = 42700 | train loss = 0.0000\n",
      "epoch = 142 | current step = 42800 | train loss = 0.0001\n",
      "epoch = 142 | current step = 42900 | train loss = 0.0000\n",
      "Average train loss: 0.000005\n",
      "\n",
      "Validating epoch: 142\n",
      "epoch = 142 | i = 0 | valid loss = 0.0000\n",
      "epoch = 142 | i = 500 | valid loss = 0.0000\n",
      "epoch = 142 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057669 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 143. Learning rate: 1.0000e-06\n",
      "epoch = 143 | current step = 43000 | train loss = 0.0000\n",
      "epoch = 143 | current step = 43100 | train loss = 0.0000\n",
      "epoch = 143 | current step = 43200 | train loss = 0.0000\n",
      "Average train loss: 0.000018\n",
      "\n",
      "Validating epoch: 143\n",
      "epoch = 143 | i = 0 | valid loss = 0.0000\n",
      "epoch = 143 | i = 500 | valid loss = 0.0000\n",
      "epoch = 143 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060782 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 144. Learning rate: 1.0000e-06\n",
      "epoch = 144 | current step = 43300 | train loss = 0.0000\n",
      "epoch = 144 | current step = 43400 | train loss = 0.0000\n",
      "epoch = 144 | current step = 43500 | train loss = 0.0000\n",
      "Average train loss: 0.000011\n",
      "\n",
      "Validating epoch: 144\n",
      "epoch = 144 | i = 0 | valid loss = 0.0000\n",
      "epoch = 144 | i = 500 | valid loss = 0.0000\n",
      "epoch = 144 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062645 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 145. Learning rate: 1.0000e-06\n",
      "epoch = 145 | current step = 43600 | train loss = 0.0000\n",
      "epoch = 145 | current step = 43700 | train loss = 0.0003\n",
      "epoch = 145 | current step = 43800 | train loss = 0.0000\n",
      "Average train loss: 0.000011\n",
      "\n",
      "Validating epoch: 145\n",
      "epoch = 145 | i = 0 | valid loss = 0.0000\n",
      "epoch = 145 | i = 500 | valid loss = 0.0000\n",
      "epoch = 145 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061890 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 146. Learning rate: 1.0000e-06\n",
      "epoch = 146 | current step = 43900 | train loss = 0.0000\n",
      "epoch = 146 | current step = 44000 | train loss = 0.0000\n",
      "epoch = 146 | current step = 44100 | train loss = 0.0000\n",
      "Average train loss: 0.000008\n",
      "\n",
      "Validating epoch: 146\n",
      "epoch = 146 | i = 0 | valid loss = 0.0000\n",
      "epoch = 146 | i = 500 | valid loss = 0.0000\n",
      "epoch = 146 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060415 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 147. Learning rate: 1.0000e-06\n",
      "epoch = 147 | current step = 44200 | train loss = 0.0000\n",
      "epoch = 147 | current step = 44300 | train loss = 0.0000\n",
      "epoch = 147 | current step = 44400 | train loss = 0.0000\n",
      "Average train loss: 0.000010\n",
      "\n",
      "Validating epoch: 147\n",
      "epoch = 147 | i = 0 | valid loss = 0.0000\n",
      "epoch = 147 | i = 500 | valid loss = 0.0000\n",
      "epoch = 147 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059791 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 148. Learning rate: 1.0000e-06\n",
      "epoch = 148 | current step = 44500 | train loss = 0.0000\n",
      "epoch = 148 | current step = 44600 | train loss = 0.0000\n",
      "epoch = 148 | current step = 44700 | train loss = 0.0000\n",
      "Average train loss: 0.000006\n",
      "\n",
      "Validating epoch: 148\n",
      "epoch = 148 | i = 0 | valid loss = 0.0000\n",
      "epoch = 148 | i = 500 | valid loss = 0.0000\n",
      "epoch = 148 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063049 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 149. Learning rate: 1.0000e-06\n",
      "epoch = 149 | current step = 44800 | train loss = 0.0000\n",
      "epoch = 149 | current step = 44900 | train loss = 0.0000\n",
      "epoch = 149 | current step = 45000 | train loss = 0.0000\n",
      "Average train loss: 0.000010\n",
      "\n",
      "Validating epoch: 149\n",
      "epoch = 149 | i = 0 | valid loss = 0.0000\n",
      "epoch = 149 | i = 500 | valid loss = 0.0000\n",
      "epoch = 149 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058050 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "checkpoint at epoch 150 saved!\n",
      "\n",
      "Training epoch: 150. Learning rate: 1.0000e-06\n",
      "epoch = 150 | current step = 45100 | train loss = 0.0000\n",
      "epoch = 150 | current step = 45200 | train loss = 0.0000\n",
      "epoch = 150 | current step = 45300 | train loss = 0.0000\n",
      "Average train loss: 0.000009\n",
      "\n",
      "Validating epoch: 150\n",
      "epoch = 150 | i = 0 | valid loss = 0.0000\n",
      "epoch = 150 | i = 500 | valid loss = 0.0000\n",
      "epoch = 150 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.066011 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 151. Learning rate: 1.0000e-06\n",
      "epoch = 151 | current step = 45400 | train loss = 0.0000\n",
      "epoch = 151 | current step = 45500 | train loss = 0.0000\n",
      "epoch = 151 | current step = 45600 | train loss = 0.0000\n",
      "Average train loss: 0.000096\n",
      "\n",
      "Validating epoch: 151\n",
      "epoch = 151 | i = 0 | valid loss = 0.0000\n",
      "epoch = 151 | i = 500 | valid loss = 0.0000\n",
      "epoch = 151 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060942 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 152. Learning rate: 1.0000e-06\n",
      "epoch = 152 | current step = 45700 | train loss = 0.0000\n",
      "epoch = 152 | current step = 45800 | train loss = 0.0000\n",
      "epoch = 152 | current step = 45900 | train loss = 0.0001\n",
      "Average train loss: 0.000253\n",
      "\n",
      "Validating epoch: 152\n",
      "epoch = 152 | i = 0 | valid loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 152 | i = 500 | valid loss = 0.0000\n",
      "epoch = 152 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.068233 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 153. Learning rate: 1.0000e-06\n",
      "epoch = 153 | current step = 46000 | train loss = 0.0000\n",
      "epoch = 153 | current step = 46100 | train loss = 0.0000\n",
      "epoch = 153 | current step = 46200 | train loss = 0.0000\n",
      "Average train loss: 0.000025\n",
      "\n",
      "Validating epoch: 153\n",
      "epoch = 153 | i = 0 | valid loss = 0.0000\n",
      "epoch = 153 | i = 500 | valid loss = 0.0000\n",
      "epoch = 153 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.057524 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 154. Learning rate: 1.0000e-06\n",
      "epoch = 154 | current step = 46300 | train loss = 0.0000\n",
      "epoch = 154 | current step = 46400 | train loss = 0.0000\n",
      "epoch = 154 | current step = 46500 | train loss = 0.0000\n",
      "Average train loss: 0.000005\n",
      "\n",
      "Validating epoch: 154\n",
      "epoch = 154 | i = 0 | valid loss = 0.0000\n",
      "epoch = 154 | i = 500 | valid loss = 0.0000\n",
      "epoch = 154 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063858 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 155. Learning rate: 1.0000e-06\n",
      "epoch = 155 | current step = 46600 | train loss = 0.0000\n",
      "epoch = 155 | current step = 46700 | train loss = 0.0000\n",
      "epoch = 155 | current step = 46800 | train loss = 0.0000\n",
      "Average train loss: 0.000034\n",
      "\n",
      "Validating epoch: 155\n",
      "epoch = 155 | i = 0 | valid loss = 0.0000\n",
      "epoch = 155 | i = 500 | valid loss = 0.0000\n",
      "epoch = 155 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061013 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 156. Learning rate: 1.0000e-06\n",
      "epoch = 156 | current step = 46900 | train loss = 0.0000\n",
      "epoch = 156 | current step = 47000 | train loss = 0.0000\n",
      "epoch = 156 | current step = 47100 | train loss = 0.0000\n",
      "Average train loss: 0.000032\n",
      "\n",
      "Validating epoch: 156\n",
      "epoch = 156 | i = 0 | valid loss = 0.0000\n",
      "epoch = 156 | i = 500 | valid loss = 0.0000\n",
      "epoch = 156 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065016 | Accuracy: 0.9917 | Recall: 0.9800 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 157. Learning rate: 1.0000e-06\n",
      "epoch = 157 | current step = 47200 | train loss = 0.0000\n",
      "epoch = 157 | current step = 47300 | train loss = 0.0000\n",
      "epoch = 157 | current step = 47400 | train loss = 0.0000\n",
      "Average train loss: 0.000023\n",
      "\n",
      "Validating epoch: 157\n",
      "epoch = 157 | i = 0 | valid loss = 0.0000\n",
      "epoch = 157 | i = 500 | valid loss = 0.0000\n",
      "epoch = 157 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058958 | Accuracy: 0.9925 | Recall: 0.9850 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 158. Learning rate: 1.0000e-06\n",
      "epoch = 158 | current step = 47500 | train loss = 0.0000\n",
      "epoch = 158 | current step = 47600 | train loss = 0.0000\n",
      "epoch = 158 | current step = 47700 | train loss = 0.0000\n",
      "Average train loss: 0.000060\n",
      "\n",
      "Validating epoch: 158\n",
      "epoch = 158 | i = 0 | valid loss = 0.0000\n",
      "epoch = 158 | i = 500 | valid loss = 0.0000\n",
      "epoch = 158 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063418 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 159. Learning rate: 1.0000e-06\n",
      "epoch = 159 | current step = 47800 | train loss = 0.0000\n",
      "epoch = 159 | current step = 47900 | train loss = 0.0000\n",
      "epoch = 159 | current step = 48000 | train loss = 0.0005\n",
      "Average train loss: 0.000012\n",
      "\n",
      "Validating epoch: 159\n",
      "epoch = 159 | i = 0 | valid loss = 0.0000\n",
      "epoch = 159 | i = 500 | valid loss = 0.0000\n",
      "epoch = 159 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.068268 | Accuracy: 0.9917 | Recall: 0.9800 | Precision: 0.9949\n",
      "checkpoint at epoch 160 saved!\n",
      "\n",
      "Training epoch: 160. Learning rate: 1.0000e-06\n",
      "epoch = 160 | current step = 48100 | train loss = 0.0000\n",
      "epoch = 160 | current step = 48200 | train loss = 0.0000\n",
      "epoch = 160 | current step = 48300 | train loss = 0.0000\n",
      "Average train loss: 0.000011\n",
      "\n",
      "Validating epoch: 160\n",
      "epoch = 160 | i = 0 | valid loss = 0.0000\n",
      "epoch = 160 | i = 500 | valid loss = 0.0000\n",
      "epoch = 160 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061390 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 161. Learning rate: 1.0000e-06\n",
      "epoch = 161 | current step = 48400 | train loss = 0.0000\n",
      "epoch = 161 | current step = 48500 | train loss = 0.0000\n",
      "epoch = 161 | current step = 48600 | train loss = 0.0000\n",
      "Average train loss: 0.000024\n",
      "\n",
      "Validating epoch: 161\n",
      "epoch = 161 | i = 0 | valid loss = 0.0000\n",
      "epoch = 161 | i = 500 | valid loss = 0.0000\n",
      "epoch = 161 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062162 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 162. Learning rate: 1.0000e-06\n",
      "epoch = 162 | current step = 48700 | train loss = 0.0000\n",
      "epoch = 162 | current step = 48800 | train loss = 0.0000\n",
      "epoch = 162 | current step = 48900 | train loss = 0.0000\n",
      "Average train loss: 0.000079\n",
      "\n",
      "Validating epoch: 162\n",
      "epoch = 162 | i = 0 | valid loss = 0.0000\n",
      "epoch = 162 | i = 500 | valid loss = 0.0000\n",
      "epoch = 162 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065012 | Accuracy: 0.9925 | Recall: 0.9825 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 163. Learning rate: 1.0000e-06\n",
      "epoch = 163 | current step = 49000 | train loss = 0.0000\n",
      "epoch = 163 | current step = 49100 | train loss = 0.0000\n",
      "epoch = 163 | current step = 49200 | train loss = 0.0004\n",
      "Average train loss: 0.000010\n",
      "\n",
      "Validating epoch: 163\n",
      "epoch = 163 | i = 0 | valid loss = 0.0000\n",
      "epoch = 163 | i = 500 | valid loss = 0.0000\n",
      "epoch = 163 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.066518 | Accuracy: 0.9900 | Recall: 0.9775 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 164. Learning rate: 1.0000e-06\n",
      "epoch = 164 | current step = 49300 | train loss = 0.0000\n",
      "epoch = 164 | current step = 49400 | train loss = 0.0000\n",
      "epoch = 164 | current step = 49500 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 164\n",
      "epoch = 164 | i = 0 | valid loss = 0.0000\n",
      "epoch = 164 | i = 500 | valid loss = 0.0000\n",
      "epoch = 164 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061503 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 165. Learning rate: 1.0000e-06\n",
      "epoch = 165 | current step = 49600 | train loss = 0.0000\n",
      "epoch = 165 | current step = 49700 | train loss = 0.0000\n",
      "epoch = 165 | current step = 49800 | train loss = 0.0000\n",
      "Average train loss: 0.000046\n",
      "\n",
      "Validating epoch: 165\n",
      "epoch = 165 | i = 0 | valid loss = 0.0000\n",
      "epoch = 165 | i = 500 | valid loss = 0.0000\n",
      "epoch = 165 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059913 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 166. Learning rate: 1.0000e-06\n",
      "epoch = 166 | current step = 49900 | train loss = 0.0000\n",
      "epoch = 166 | current step = 50000 | train loss = 0.0000\n",
      "epoch = 166 | current step = 50100 | train loss = 0.0000\n",
      "Average train loss: 0.000011\n",
      "\n",
      "Validating epoch: 166\n",
      "epoch = 166 | i = 0 | valid loss = 0.0000\n",
      "epoch = 166 | i = 500 | valid loss = 0.0000\n",
      "epoch = 166 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059480 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 167. Learning rate: 1.0000e-06\n",
      "epoch = 167 | current step = 50200 | train loss = 0.0000\n",
      "epoch = 167 | current step = 50300 | train loss = 0.0000\n",
      "epoch = 167 | current step = 50400 | train loss = 0.0000\n",
      "Average train loss: 0.000014\n",
      "\n",
      "Validating epoch: 167\n",
      "epoch = 167 | i = 0 | valid loss = 0.0000\n",
      "epoch = 167 | i = 500 | valid loss = 0.0000\n",
      "epoch = 167 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059782 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 168. Learning rate: 1.0000e-06\n",
      "epoch = 168 | current step = 50500 | train loss = 0.0000\n",
      "epoch = 168 | current step = 50600 | train loss = 0.0000\n",
      "epoch = 168 | current step = 50700 | train loss = 0.0000\n",
      "Average train loss: 0.000015\n",
      "\n",
      "Validating epoch: 168\n",
      "epoch = 168 | i = 0 | valid loss = 0.0000\n",
      "epoch = 168 | i = 500 | valid loss = 0.0000\n",
      "epoch = 168 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063459 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 169. Learning rate: 1.0000e-06\n",
      "epoch = 169 | current step = 50800 | train loss = 0.0000\n",
      "epoch = 169 | current step = 50900 | train loss = 0.0000\n",
      "epoch = 169 | current step = 51000 | train loss = 0.0000\n",
      "Average train loss: 0.000006\n",
      "\n",
      "Validating epoch: 169\n",
      "epoch = 169 | i = 0 | valid loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 169 | i = 500 | valid loss = 0.0000\n",
      "epoch = 169 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062878 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "checkpoint at epoch 170 saved!\n",
      "\n",
      "Training epoch: 170. Learning rate: 1.0000e-06\n",
      "epoch = 170 | current step = 51100 | train loss = 0.0000\n",
      "epoch = 170 | current step = 51200 | train loss = 0.0000\n",
      "epoch = 170 | current step = 51300 | train loss = 0.0000\n",
      "Average train loss: 0.000004\n",
      "\n",
      "Validating epoch: 170\n",
      "epoch = 170 | i = 0 | valid loss = 0.0000\n",
      "epoch = 170 | i = 500 | valid loss = 0.0000\n",
      "epoch = 170 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061231 | Accuracy: 0.9908 | Recall: 0.9850 | Precision: 0.9875\n",
      "\n",
      "Training epoch: 171. Learning rate: 1.0000e-06\n",
      "epoch = 171 | current step = 51400 | train loss = 0.0000\n",
      "epoch = 171 | current step = 51500 | train loss = 0.0000\n",
      "epoch = 171 | current step = 51600 | train loss = 0.0000\n",
      "Average train loss: 0.000023\n",
      "\n",
      "Validating epoch: 171\n",
      "epoch = 171 | i = 0 | valid loss = 0.0000\n",
      "epoch = 171 | i = 500 | valid loss = 0.0000\n",
      "epoch = 171 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059405 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 172. Learning rate: 1.0000e-06\n",
      "epoch = 172 | current step = 51700 | train loss = 0.0000\n",
      "epoch = 172 | current step = 51800 | train loss = 0.0000\n",
      "epoch = 172 | current step = 51900 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 172\n",
      "epoch = 172 | i = 0 | valid loss = 0.0000\n",
      "epoch = 172 | i = 500 | valid loss = 0.0000\n",
      "epoch = 172 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.064561 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 173. Learning rate: 1.0000e-06\n",
      "epoch = 173 | current step = 52000 | train loss = 0.0000\n",
      "epoch = 173 | current step = 52100 | train loss = 0.0000\n",
      "epoch = 173 | current step = 52200 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 173\n",
      "epoch = 173 | i = 0 | valid loss = 0.0000\n",
      "epoch = 173 | i = 500 | valid loss = 0.0000\n",
      "epoch = 173 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062995 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 174. Learning rate: 1.0000e-06\n",
      "epoch = 174 | current step = 52300 | train loss = 0.0000\n",
      "epoch = 174 | current step = 52400 | train loss = 0.0000\n",
      "epoch = 174 | current step = 52500 | train loss = 0.0000\n",
      "Average train loss: 0.000015\n",
      "\n",
      "Validating epoch: 174\n",
      "epoch = 174 | i = 0 | valid loss = 0.0000\n",
      "epoch = 174 | i = 500 | valid loss = 0.0000\n",
      "epoch = 174 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063650 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 175. Learning rate: 1.0000e-06\n",
      "epoch = 175 | current step = 52600 | train loss = 0.0000\n",
      "epoch = 175 | current step = 52700 | train loss = 0.0000\n",
      "epoch = 175 | current step = 52800 | train loss = 0.0000\n",
      "Average train loss: 0.000023\n",
      "\n",
      "Validating epoch: 175\n",
      "epoch = 175 | i = 0 | valid loss = 0.0000\n",
      "epoch = 175 | i = 500 | valid loss = 0.0000\n",
      "epoch = 175 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060207 | Accuracy: 0.9900 | Recall: 0.9800 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 176. Learning rate: 1.0000e-06\n",
      "epoch = 176 | current step = 52900 | train loss = 0.0000\n",
      "epoch = 176 | current step = 53000 | train loss = 0.0000\n",
      "epoch = 176 | current step = 53100 | train loss = 0.0000\n",
      "Average train loss: 0.000010\n",
      "\n",
      "Validating epoch: 176\n",
      "epoch = 176 | i = 0 | valid loss = 0.0000\n",
      "epoch = 176 | i = 500 | valid loss = 0.0000\n",
      "epoch = 176 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.068836 | Accuracy: 0.9908 | Recall: 0.9775 | Precision: 0.9949\n",
      "\n",
      "Training epoch: 177. Learning rate: 1.0000e-06\n",
      "epoch = 177 | current step = 53200 | train loss = 0.0000\n",
      "epoch = 177 | current step = 53300 | train loss = 0.0000\n",
      "epoch = 177 | current step = 53400 | train loss = 0.0000\n",
      "Average train loss: 0.000021\n",
      "\n",
      "Validating epoch: 177\n",
      "epoch = 177 | i = 0 | valid loss = 0.0000\n",
      "epoch = 177 | i = 500 | valid loss = 0.0000\n",
      "epoch = 177 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.063203 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 178. Learning rate: 1.0000e-06\n",
      "epoch = 178 | current step = 53500 | train loss = 0.0000\n",
      "epoch = 178 | current step = 53600 | train loss = 0.0000\n",
      "epoch = 178 | current step = 53700 | train loss = 0.0000\n",
      "Average train loss: 0.000002\n",
      "\n",
      "Validating epoch: 178\n",
      "epoch = 178 | i = 0 | valid loss = 0.0000\n",
      "epoch = 178 | i = 500 | valid loss = 0.0000\n",
      "epoch = 178 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058312 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 179. Learning rate: 1.0000e-06\n",
      "epoch = 179 | current step = 53800 | train loss = 0.0000\n",
      "epoch = 179 | current step = 53900 | train loss = 0.0000\n",
      "epoch = 179 | current step = 54000 | train loss = 0.0000\n",
      "Average train loss: 0.000018\n",
      "\n",
      "Validating epoch: 179\n",
      "epoch = 179 | i = 0 | valid loss = 0.0000\n",
      "epoch = 179 | i = 500 | valid loss = 0.0000\n",
      "epoch = 179 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.058592 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "checkpoint at epoch 180 saved!\n",
      "\n",
      "Training epoch: 180. Learning rate: 1.0000e-06\n",
      "epoch = 180 | current step = 54100 | train loss = 0.0000\n",
      "epoch = 180 | current step = 54200 | train loss = 0.0000\n",
      "epoch = 180 | current step = 54300 | train loss = 0.0000\n",
      "Average train loss: 0.000006\n",
      "\n",
      "Validating epoch: 180\n",
      "epoch = 180 | i = 0 | valid loss = 0.0000\n",
      "epoch = 180 | i = 500 | valid loss = 0.0000\n",
      "epoch = 180 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062538 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 181. Learning rate: 1.0000e-06\n",
      "epoch = 181 | current step = 54400 | train loss = 0.0000\n",
      "epoch = 181 | current step = 54500 | train loss = 0.0000\n",
      "epoch = 181 | current step = 54600 | train loss = 0.0000\n",
      "Average train loss: 0.000003\n",
      "\n",
      "Validating epoch: 181\n",
      "epoch = 181 | i = 0 | valid loss = 0.0000\n",
      "epoch = 181 | i = 500 | valid loss = 0.0000\n",
      "epoch = 181 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061939 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 182. Learning rate: 1.0000e-06\n",
      "epoch = 182 | current step = 54700 | train loss = 0.0000\n",
      "epoch = 182 | current step = 54800 | train loss = 0.0000\n",
      "epoch = 182 | current step = 54900 | train loss = 0.0000\n",
      "Average train loss: 0.000009\n",
      "\n",
      "Validating epoch: 182\n",
      "epoch = 182 | i = 0 | valid loss = 0.0000\n",
      "epoch = 182 | i = 500 | valid loss = 0.0000\n",
      "epoch = 182 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.059939 | Accuracy: 0.9900 | Recall: 0.9825 | Precision: 0.9874\n",
      "\n",
      "Training epoch: 183. Learning rate: 1.0000e-06\n",
      "epoch = 183 | current step = 55000 | train loss = 0.0000\n",
      "epoch = 183 | current step = 55100 | train loss = 0.0000\n",
      "epoch = 183 | current step = 55200 | train loss = 0.0000\n",
      "Average train loss: 0.000002\n",
      "\n",
      "Validating epoch: 183\n",
      "epoch = 183 | i = 0 | valid loss = 0.0000\n",
      "epoch = 183 | i = 500 | valid loss = 0.0000\n",
      "epoch = 183 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.064141 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 184. Learning rate: 1.0000e-06\n",
      "epoch = 184 | current step = 55300 | train loss = 0.0000\n",
      "epoch = 184 | current step = 55400 | train loss = 0.0000\n",
      "epoch = 184 | current step = 55500 | train loss = 0.0000\n",
      "Average train loss: 0.000036\n",
      "\n",
      "Validating epoch: 184\n",
      "epoch = 184 | i = 0 | valid loss = 0.0000\n",
      "epoch = 184 | i = 500 | valid loss = 0.0000\n",
      "epoch = 184 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.066516 | Accuracy: 0.9908 | Recall: 0.9800 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 185. Learning rate: 1.0000e-06\n",
      "epoch = 185 | current step = 55600 | train loss = 0.0000\n",
      "epoch = 185 | current step = 55700 | train loss = 0.0000\n",
      "epoch = 185 | current step = 55800 | train loss = 0.0000\n",
      "Average train loss: 0.000011\n",
      "\n",
      "Validating epoch: 185\n",
      "epoch = 185 | i = 0 | valid loss = 0.0000\n",
      "epoch = 185 | i = 500 | valid loss = 0.0000\n",
      "epoch = 185 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061592 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 186. Learning rate: 1.0000e-06\n",
      "epoch = 186 | current step = 55900 | train loss = 0.0000\n",
      "epoch = 186 | current step = 56000 | train loss = 0.0000\n",
      "epoch = 186 | current step = 56100 | train loss = 0.0000\n",
      "Average train loss: 0.000012\n",
      "\n",
      "Validating epoch: 186\n",
      "epoch = 186 | i = 0 | valid loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 186 | i = 500 | valid loss = 0.0000\n",
      "epoch = 186 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.067315 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 187. Learning rate: 1.0000e-06\n",
      "epoch = 187 | current step = 56200 | train loss = 0.0000\n",
      "epoch = 187 | current step = 56300 | train loss = 0.0000\n",
      "epoch = 187 | current step = 56400 | train loss = 0.0000\n",
      "Average train loss: 0.000005\n",
      "\n",
      "Validating epoch: 187\n",
      "epoch = 187 | i = 0 | valid loss = 0.0000\n",
      "epoch = 187 | i = 500 | valid loss = 0.0000\n",
      "epoch = 187 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.061629 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 188. Learning rate: 1.0000e-06\n",
      "epoch = 188 | current step = 56500 | train loss = 0.0000\n",
      "epoch = 188 | current step = 56600 | train loss = 0.0000\n",
      "epoch = 188 | current step = 56700 | train loss = 0.0000\n",
      "Average train loss: 0.000006\n",
      "\n",
      "Validating epoch: 188\n",
      "epoch = 188 | i = 0 | valid loss = 0.0000\n",
      "epoch = 188 | i = 500 | valid loss = 0.0000\n",
      "epoch = 188 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.067347 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 189. Learning rate: 1.0000e-06\n",
      "epoch = 189 | current step = 56800 | train loss = 0.0000\n",
      "epoch = 189 | current step = 56900 | train loss = 0.0000\n",
      "epoch = 189 | current step = 57000 | train loss = 0.0000\n",
      "Average train loss: 0.000004\n",
      "\n",
      "Validating epoch: 189\n",
      "epoch = 189 | i = 0 | valid loss = 0.0000\n",
      "epoch = 189 | i = 500 | valid loss = 0.0000\n",
      "epoch = 189 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.064238 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "checkpoint at epoch 190 saved!\n",
      "\n",
      "Training epoch: 190. Learning rate: 1.0000e-06\n",
      "epoch = 190 | current step = 57100 | train loss = 0.0000\n",
      "epoch = 190 | current step = 57200 | train loss = 0.0000\n",
      "epoch = 190 | current step = 57300 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 190\n",
      "epoch = 190 | i = 0 | valid loss = 0.0000\n",
      "epoch = 190 | i = 500 | valid loss = 0.0000\n",
      "epoch = 190 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065605 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 191. Learning rate: 1.0000e-06\n",
      "epoch = 191 | current step = 57400 | train loss = 0.0000\n",
      "epoch = 191 | current step = 57500 | train loss = 0.0000\n",
      "epoch = 191 | current step = 57600 | train loss = 0.0001\n",
      "Average train loss: 0.000004\n",
      "\n",
      "Validating epoch: 191\n",
      "epoch = 191 | i = 0 | valid loss = 0.0000\n",
      "epoch = 191 | i = 500 | valid loss = 0.0000\n",
      "epoch = 191 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.064124 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "\n",
      "Training epoch: 192. Learning rate: 1.0000e-06\n",
      "epoch = 192 | current step = 57700 | train loss = 0.0000\n",
      "epoch = 192 | current step = 57800 | train loss = 0.0000\n",
      "epoch = 192 | current step = 57900 | train loss = 0.0000\n",
      "Average train loss: 0.000007\n",
      "\n",
      "Validating epoch: 192\n",
      "epoch = 192 | i = 0 | valid loss = 0.0000\n",
      "epoch = 192 | i = 500 | valid loss = 0.0000\n",
      "epoch = 192 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060423 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 193. Learning rate: 1.0000e-06\n",
      "epoch = 193 | current step = 58000 | train loss = 0.0000\n",
      "epoch = 193 | current step = 58100 | train loss = 0.0000\n",
      "epoch = 193 | current step = 58200 | train loss = 0.0000\n",
      "Average train loss: 0.000004\n",
      "\n",
      "Validating epoch: 193\n",
      "epoch = 193 | i = 0 | valid loss = 0.0000\n",
      "epoch = 193 | i = 500 | valid loss = 0.0000\n",
      "epoch = 193 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065880 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 194. Learning rate: 1.0000e-06\n",
      "epoch = 194 | current step = 58300 | train loss = 0.0000\n",
      "epoch = 194 | current step = 58400 | train loss = 0.0000\n",
      "epoch = 194 | current step = 58500 | train loss = 0.0000\n",
      "Average train loss: 0.000061\n",
      "\n",
      "Validating epoch: 194\n",
      "epoch = 194 | i = 0 | valid loss = 0.0000\n",
      "epoch = 194 | i = 500 | valid loss = 0.0000\n",
      "epoch = 194 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065967 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 195. Learning rate: 1.0000e-06\n",
      "epoch = 195 | current step = 58600 | train loss = 0.0000\n",
      "epoch = 195 | current step = 58700 | train loss = 0.0000\n",
      "epoch = 195 | current step = 58800 | train loss = 0.0000\n",
      "Average train loss: 0.000006\n",
      "\n",
      "Validating epoch: 195\n",
      "epoch = 195 | i = 0 | valid loss = 0.0000\n",
      "epoch = 195 | i = 500 | valid loss = 0.0000\n",
      "epoch = 195 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.065060 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 196. Learning rate: 1.0000e-06\n",
      "epoch = 196 | current step = 58900 | train loss = 0.0000\n",
      "epoch = 196 | current step = 59000 | train loss = 0.0000\n",
      "epoch = 196 | current step = 59100 | train loss = 0.0000\n",
      "Average train loss: 0.000004\n",
      "\n",
      "Validating epoch: 196\n",
      "epoch = 196 | i = 0 | valid loss = 0.0000\n",
      "epoch = 196 | i = 500 | valid loss = 0.0000\n",
      "epoch = 196 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.060717 | Accuracy: 0.9917 | Recall: 0.9850 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 197. Learning rate: 1.0000e-06\n",
      "epoch = 197 | current step = 59200 | train loss = 0.0000\n",
      "epoch = 197 | current step = 59300 | train loss = 0.0000\n",
      "epoch = 197 | current step = 59400 | train loss = 0.0000\n",
      "Average train loss: 0.000002\n",
      "\n",
      "Validating epoch: 197\n",
      "epoch = 197 | i = 0 | valid loss = 0.0000\n",
      "epoch = 197 | i = 500 | valid loss = 0.0000\n",
      "epoch = 197 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.064346 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 198. Learning rate: 1.0000e-06\n",
      "epoch = 198 | current step = 59500 | train loss = 0.0000\n",
      "epoch = 198 | current step = 59600 | train loss = 0.0000\n",
      "epoch = 198 | current step = 59700 | train loss = 0.0000\n",
      "Average train loss: 0.000003\n",
      "\n",
      "Validating epoch: 198\n",
      "epoch = 198 | i = 0 | valid loss = 0.0000\n",
      "epoch = 198 | i = 500 | valid loss = 0.0000\n",
      "epoch = 198 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.062127 | Accuracy: 0.9908 | Recall: 0.9825 | Precision: 0.9899\n",
      "\n",
      "Training epoch: 199. Learning rate: 1.0000e-06\n",
      "epoch = 199 | current step = 59800 | train loss = 0.0000\n",
      "epoch = 199 | current step = 59900 | train loss = 0.0000\n",
      "epoch = 199 | current step = 60000 | train loss = 0.0003\n",
      "Average train loss: 0.000005\n",
      "\n",
      "Validating epoch: 199\n",
      "epoch = 199 | i = 0 | valid loss = 0.0000\n",
      "epoch = 199 | i = 500 | valid loss = 0.0000\n",
      "epoch = 199 | i = 1000 | valid loss = 0.0000\n",
      "Average valid loss: 0.066300 | Accuracy: 0.9917 | Recall: 0.9825 | Precision: 0.9924\n",
      "checkpoint at epoch 200 saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    log_and_print(logger, 'Training epoch: {}. Learning rate: {:.4e}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, item in enumerate(train_dataloader):\n",
    "        data = item['imgs']\n",
    "        target = item['label']\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad() # clear the gradients of all optimized variables\n",
    "        output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tb_logger.add_scalar('loss_train', loss.item(), current_step)\n",
    "        current_step += 1\n",
    "        if current_step % 100 == 0:\n",
    "            log_and_print(logger, 'epoch = {:d} | current step = {:d} | train loss = {:.4f}'.format(epoch, current_step, loss.item()))\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    log_and_print(logger, 'Average train loss: {:.6f}\\n'.format(train_loss))\n",
    "\n",
    "    log_and_print(logger, 'Validating epoch: {}'.format(epoch))\n",
    "    valid_loss = 0.0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, item in enumerate(valid_dataloader):\n",
    "            data = item['imgs']\n",
    "            target = item['label']\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            label_true = target.item()\n",
    "            label_pred = torch.argmax(output).item()\n",
    "            if label_true == 1 and label_pred == 1:\n",
    "                TP += 1\n",
    "            elif label_true == 0 and label_pred == 0:\n",
    "                TN += 1\n",
    "            elif label_true == 0 and label_pred == 1:\n",
    "                FP += 1\n",
    "            elif label_true == 1 and label_pred == 0:\n",
    "                FN += 1\n",
    "            else:\n",
    "                assert False, 'error label'\n",
    "            if i % 500 == 0:\n",
    "                log_and_print(logger, 'epoch = {:d} | i = {:d} | valid loss = {:.4f}'.format(epoch, i, loss.item()))\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    lr_scheduler.step(valid_loss)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = (TP) / (TP + FP)\n",
    "    recall = (TP) / (TP + FN)\n",
    "    tb_logger.add_scalar('loss_valid', valid_loss, epoch)\n",
    "    tb_logger.add_scalar('accuracy_valid', accuracy, epoch)\n",
    "    tb_logger.add_scalar('precision_valid', precision, epoch)\n",
    "    tb_logger.add_scalar('recall_valid', recall, epoch)\n",
    "    log_and_print(logger, 'Average valid loss: {:.6f} | Accuracy: {:.4f} | Recall: {:.4f} | Precision: {:.4f}'.format(valid_loss, accuracy, recall, precision))\n",
    "\n",
    "    if valid_loss < valid_loss_min:\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "        save_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"iter\": current_step,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"loss\": valid_loss_min,\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "        }\n",
    "        save_path = os.path.join(experiment_dir, 'checkpoint_best_loss.pth.tar')\n",
    "        torch.save(save_dict, save_path)\n",
    "        log_and_print(logger, 'best checkpoint saved!')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"iter\": current_step,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"loss\": valid_loss_min,\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "        }\n",
    "        save_path = os.path.join(experiment_dir, 'checkpoint_epoch_{:03d}.pth.tar'.format(epoch + 1))\n",
    "        torch.save(save_dict, save_path)\n",
    "        log_and_print(logger, 'checkpoint at epoch {:03d} saved!'.format(epoch + 1))\n",
    "\n",
    "    log_and_print(logger, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing\n",
    "\n",
    "We validate and test two models on the splitted validation and test set, respectively; they are the model with the best validation loss (denoted as model_best) and the model at the last epoch of 200 (denoted as model_last)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_path_list, true_class_list, path):\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    from torchvision import models\n",
    "    from torchvision import transforms\n",
    "\n",
    "    class resnet(torch.nn.Module):\n",
    "        def __init__(self, pretrained=False):\n",
    "            super(resnet, self).__init__()\n",
    "            if pretrained == True:\n",
    "                model = models.resnet50(pretrained = True)\n",
    "            else:\n",
    "                model = models.resnet50(pretrained = False)\n",
    "\n",
    "            self.slice1 = torch.nn.Sequential()\n",
    "            self.slice1.add_module(str(1), model.conv1)\n",
    "            self.slice1.add_module(str(2), model.bn1)\n",
    "            self.slice1.add_module(str(3), model.relu)\n",
    "            self.slice1.add_module(str(4), model.maxpool)\n",
    "            self.slice1.add_module(str(5), model.layer1)\n",
    "            self.slice1.add_module(str(6), model.layer2)\n",
    "            self.slice1.add_module(str(7), model.layer3)\n",
    "            \n",
    "            model_other = models.resnet50(pretrained = False)\n",
    "\n",
    "            self.slice2 = model_other.layer4\n",
    "            self.avgpool = model_other.avgpool\n",
    "\n",
    "            self.classifier = torch.nn.Sequential()\n",
    "            self.classifier.add_module(str(1), model_other.fc)\n",
    "            self.classifier.add_module(str(2), torch.nn.ReLU(inplace=True))\n",
    "            self.classifier.add_module(str(3), torch.nn.Linear(1000, 2))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.slice1(x)\n",
    "            x = self.slice2(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "    # load the model\n",
    "    model = resnet(pretrained=False)\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    # prepare data\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    for img_path, true_class in zip(img_path_list, true_class_list):\n",
    "        img = Image.open(img_path)\n",
    "        img = transform(img).unsqueeze(0)\n",
    "        img = img.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "        pred_class = torch.argmax(output).item()\n",
    "\n",
    "        if true_class == 1 and pred_class == 1:\n",
    "            TP += 1\n",
    "        elif true_class == 0 and pred_class == 0:\n",
    "            TN += 1\n",
    "        elif true_class == 0 and pred_class == 1:\n",
    "            FP += 1\n",
    "        elif true_class == 1 and pred_class == 0:\n",
    "            FN += 1\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = (TP) / (TP + FP)\n",
    "    recall = (TP) / (TP + FN)\n",
    "    print('TP = {:d}, TN = {:d}, FP = {:d}, FN = {:d}'.format(TP, TN, FP, FN))\n",
    "\n",
    "    return accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation results for model_best:\n",
      "TP = 395, TN = 797, FP = 3, FN = 5\n",
      "accuracy = 0.993333, recall = 0.987500, precision = 0.992462\n",
      "\n",
      "validation results for model_last:\n",
      "TP = 393, TN = 797, FP = 3, FN = 7\n",
      "accuracy = 0.991667, recall = 0.982500, precision = 0.992424\n"
     ]
    }
   ],
   "source": [
    "json_path_test = '/home/felix/disk1/sss/deepfake_detection/data/valid_2-1.json'\n",
    "data = json.load(open(json_path_test))\n",
    "img_path_list = [value['img_paths'] for value in data.values()]\n",
    "true_class_list = [value['label'] for value in data.values()]\n",
    "\n",
    "# validation for model_best\n",
    "print('validation results for model_best:')\n",
    "model_last_epoch = '/home/felix/disk1/sss/deepfake_detection/script/experiments/aug3_v2/checkpoint_best_loss.pth.tar'\n",
    "accuracy, recall, precision = test(img_path_list, true_class_list, model_last_epoch)\n",
    "print('accuracy = {:.6f}, recall = {:.6f}, precision = {:.6f}\\n'.format(accuracy, recall, precision))\n",
    "\n",
    "# validation for model_last\n",
    "print('validation results for model_last:')\n",
    "model_last_epoch = '/home/felix/disk1/sss/deepfake_detection/script/experiments/aug3_v2/checkpoint_epoch_200.pth.tar'\n",
    "accuracy, recall, precision = test(img_path_list, true_class_list, model_last_epoch)\n",
    "print('accuracy = {:.6f}, recall = {:.6f}, precision = {:.6f}'.format(accuracy, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing results for model_best:\n",
      "TP = 399, TN = 794, FP = 6, FN = 1\n",
      "accuracy = 0.994167, recall = 0.997500, precision = 0.985185\n",
      "\n",
      "testing results for model_last:\n",
      "TP = 399, TN = 797, FP = 3, FN = 1\n",
      "accuracy = 0.996667, recall = 0.997500, precision = 0.992537\n"
     ]
    }
   ],
   "source": [
    "json_path_test = '/home/felix/disk1/sss/deepfake_detection/data/test_2-1.json'\n",
    "data = json.load(open(json_path_test))\n",
    "img_path_list = [value['img_paths'] for value in data.values()]\n",
    "true_class_list = [value['label'] for value in data.values()]\n",
    "\n",
    "# testing for model_best\n",
    "print('testing results for model_best:')\n",
    "model_last_epoch = '/home/felix/disk1/sss/deepfake_detection/script/experiments/aug3_v2/checkpoint_best_loss.pth.tar'\n",
    "accuracy, recall, precision = test(img_path_list, true_class_list, model_last_epoch)\n",
    "print('accuracy = {:.6f}, recall = {:.6f}, precision = {:.6f}\\n'.format(accuracy, recall, precision))\n",
    "\n",
    "# testing for model_last\n",
    "print('testing results for model_last:')\n",
    "model_last_epoch = '/home/felix/disk1/sss/deepfake_detection/script/experiments/aug3_v2/checkpoint_epoch_200.pth.tar'\n",
    "accuracy, recall, precision = test(img_path_list, true_class_list, model_last_epoch)\n",
    "print('accuracy = {:.6f}, recall = {:.6f}, precision = {:.6f}'.format(accuracy, recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "After training different data spliting methods, different data augmentation methods, and different model structures, we finally validate and test two models (model_best and model_last) on the splitted validation and test set, respectively. \n",
    "\n",
    "The corresponding performance on the validation set is as follows (TP: true positive, TN: true negative, FP: false positive, FN: false negative):\n",
    "\n",
    "validation results for model_best:\n",
    "* TP = 395, TN = 797, FP = 3, FN = 5\n",
    "* accuracy = 0.993333, recall = 0.987500, precision = 0.992462\n",
    "\n",
    "validation results for model_last:\n",
    "* TP = 393, TN = 797, FP = 3, FN = 7\n",
    "* accuracy = 0.991667, recall = 0.982500, precision = 0.992424\n",
    "\n",
    "The corresponding performance on the validation set is as follows (TP: true positive, TN: true negative, FP: false positive, FN: false negative):\n",
    "\n",
    "testing results for model_best:\n",
    "* TP = 399, TN = 794, FP = 6, FN = 1\n",
    "* accuracy = 0.994167, recall = 0.997500, precision = 0.985185\n",
    "\n",
    "testing results for model_last:\n",
    "* TP = 399, TN = 797, FP = 3, FN = 1\n",
    "* accuracy = 0.996667, recall = 0.997500, precision = 0.992537\n",
    "\n",
    "The two models have similar performance on the test set, where model_last has better accuracy and precision compared with model_best. We can see that the testing performance of our modal is very good and consistent with the validation performance. Apart from the performance, we decide to select the model at the last epoch of 200 (model_last) as our final model, considering the following two reasons:\n",
    "\n",
    "1. The model at the last epoch of 200 is trained much longer.\n",
    "2. The model with the best validation loss may somehow overfit on the validation set at early epoch.\n",
    "\n",
    "So, we decide to submit model_last as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reference\n",
    "1. S. Karen and Z. Andrew, ”Very Deep Convolutional Networks for Large-Scale Image Recognition,” The 3rd International Conference on Learning Representations (ICLR2015). https://arxiv.org/abs/1409.1556\n",
    "2. K. He, X. Zhang, S. Ren and J. Sun, “Deep Residual Learning for Image Recognition,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90.\n",
    "3. R. Tolosana, R. Vera-Rodriguez, J. Fierrez, A. Morales and J. Ortega-Garcia,“DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection.” Inf. Fusion 64 (2020): 131-148."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1b598260c297da5c99b47d9e921d5f66114cf5293962c7c77ed62b25603d927"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('sjy': conda)",
   "language": "python",
   "name": "python3711jvsc74a57bd0f1b598260c297da5c99b47d9e921d5f66114cf5293962c7c77ed62b25603d927"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
